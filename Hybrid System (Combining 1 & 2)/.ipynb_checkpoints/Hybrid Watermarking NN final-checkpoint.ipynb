{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27c7a7e7",
   "metadata": {},
   "source": [
    "# Hybrid Approach for Watermarking Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63435dc",
   "metadata": {},
   "source": [
    "## Following section embeds watermarks into a resnet architecture using black box watermarking approach. The dataset used is CIFAR10.\n",
    "\n",
    "### Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bded2210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c4ff853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25962578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install matplotlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25464da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip\n",
    "# !pip install resnet20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ebb2c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e546782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from platform import python_version\n",
    "# print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da486797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img, array_to_img, ImageDataGenerator\n",
    "import gzip\n",
    "from skimage.util.noise import random_noise\n",
    "from resnet20 import resnet_v1\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from tensorflow.keras.layers import AveragePooling2D, Input, Flatten\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import math\n",
    "from typing import List, Tuple, Dict\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "import hashlib\n",
    "import concurrent.futures\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from stego import FloatBinary, str_to_bits, bits_to_str, dummy_data_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7fe9974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_layer(inputs, num_filters=16, kernel_size=3, strides=1, activation='relu', batch_normalization=True, conv_first=True):\n",
    "    # Create a convolutional layer with specified parameters\n",
    "    conv = Conv2D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=l2(1e-4))\n",
    "    # Set the input to the function to a variable called 'x'\n",
    "    x = inputs\n",
    "    # If 'conv_first' is True, apply the convolutional layer to the input\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        # If 'batch_normalization' is True, apply batch normalization to the output of the convolutional layer\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        # If 'activation' is not None, apply activation function to the output of the batch normalization layer\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    # If 'conv_first' is False, apply batch normalization to the input first, then apply the convolutional layer\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    # Return the output of the function\n",
    "    return x\n",
    "\n",
    "\n",
    "def resnet_v1(input_shape, depth, num_classes=10):\n",
    "    \"\"\"ResNet Version 1 Model builder\n",
    "    \n",
    "    args:\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "\n",
    "    return:\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 6 != 0:\n",
    "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44)')\n",
    "    # Start model definition.\n",
    "    num_filters = 16\n",
    "    num_res_blocks = int((depth - 2) / 6)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = resnet_layer(inputs=inputs)\n",
    "    # Instantiate the stack of residual units\n",
    "    for stack in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            strides = 1\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                strides = 2  # downsample\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters,\n",
    "                             strides=strides)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters,\n",
    "                             activation=None)\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "            x = Activation('relu')(x)\n",
    "        num_filters *= 2\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v1 does not use BN after last shortcut connection-ReLU\n",
    "    x = AveragePooling2D(pool_size=4)(x)\n",
    "    y = Flatten()(x)\n",
    "    y = Dense(num_classes,\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "    outputs = Activation('softmax')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a11d7752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line sets the environment variable CUDA_VISIBLE_DEVICES to '0' which specifies that only the first GPU is visible to the script.\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'\n",
    "#This line lists the available physical GPUs in the system.\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# If any GPU is available, the following code sets the memory growth option for the GPUs to True.\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# This function logs the content passed to it.\n",
    "def log(content):\n",
    "    if log_dir is not None:\n",
    "        log_file = log_dir + '/log.txt'\n",
    "        with open(log_file, 'a') as f:\n",
    "            print(content, file=f)\n",
    "\n",
    "# This function specifies the learning rate for each epoch based on the epoch number.        \n",
    "def lr_schedule(epoch):\n",
    "    lr = 1e-3\n",
    "    if epoch > 70:\n",
    "        lr *= 1e-3\n",
    "    if epoch > 60:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 40:\n",
    "        lr *= 1e-1 \n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "\n",
    "def load_data(dataset: str):\n",
    "    if dataset == 'MNIST':\n",
    "        mnist = tf.keras.datasets.mnist # load MNIST dataset\n",
    "        # split data into training and testing sets\n",
    "        (training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "        # reshape images to (28, 28, 1) size\n",
    "        training_images = training_images.reshape(60000, 28, 28, 1)\n",
    "        test_images = test_images.reshape(10000, 28, 28, 1)\n",
    "    elif dataset == 'CIFAR10':\n",
    "        cifar10 = tf.keras.datasets.cifar10\n",
    "        # split data into training and testing sets\n",
    "        (training_images, training_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "    # return training and testing images and labels\n",
    "    return training_images, training_labels, test_images, test_labels\n",
    "\n",
    "\n",
    "def get_unrelated_images(dataset: str, sample_rate):\n",
    "    \"\"\"Define a function named \"get_unrelated_images\" that takes in two parameters,\n",
    "        \n",
    "        dataset: string indicating the dataset ('MNIST' or 'CIFAR10') and\n",
    "        sample_rate: float indicating the proportion of images to use as training data.\"\"\"\n",
    "    # Create an empty list to store watermark images\n",
    "    watermark_images = []\n",
    "    # If the dataset is 'MNIST'\n",
    "    if dataset == 'MNIST':\n",
    "        # Set the file paths for the train images and train labels of 'emnist-letters' dataset\n",
    "        train_images_path = './data/emnist/emnist-letters-train-images-idx3-ubyte.gz'\n",
    "        train_labels_path = './data/emnist/emnist-letters-train-labels-idx1-ubyte.gz'\n",
    "        # Load images and labels from the train data file\n",
    "        with gzip.open(train_images_path, 'rb') as imgpath:\n",
    "            images = np.frombuffer(imgpath.read(), np.uint8, offset=16).reshape((-1, 28, 28, 1))\n",
    "        with gzip.open(train_labels_path, 'rb') as lbpath:\n",
    "            labels = np.frombuffer(lbpath.read(), np.uint8, offset=8)\n",
    "        # Check the labels of each image and store the images labeled as 23 (an unrelated class) in the watermark_images list\n",
    "        for i in range(images.shape[0]):\n",
    "            if labels[i] == 23:\n",
    "                watermark_images.append(images[i])\n",
    "    # If the dataset is 'CIFAR10'\n",
    "    elif dataset == 'CIFAR10':\n",
    "        # Load the MNIST dataset from keras datasets and store the training images and labels \n",
    "        mnist = tf.keras.datasets.mnist\n",
    "        (training_images, training_labels), (_, _) = mnist.load_data()\n",
    "        # Check the labels of each image and if it is labeled as 1 (an unrelated class), \n",
    "        # convert it into an RGB image of 32x32 dimensions and store in watermark_images list\n",
    "        for i in range(len(training_labels)):\n",
    "            if training_labels[i] == 1:\n",
    "                image = array_to_img(training_images[i].reshape(28, 28, 1))\n",
    "                image = image.convert(mode='RGB')\n",
    "                image = image.resize((32, 32))\n",
    "                image = img_to_array(image)\n",
    "                watermark_images.append(image)\n",
    "    # Shuffle the watermark images randomly\n",
    "    random.shuffle(watermark_images)\n",
    "    # Convert the watermark images list into a numpy array\n",
    "    watermark_images = np.array(watermark_images)\n",
    "    # Calculate the number of training samples based on the given sample rate\n",
    "    train_sample_number = int(len(watermark_images) * sample_rate)\n",
    "    # Split the watermark images into training and testing samples based on the calculated number of training samples\n",
    "    train_sample = watermark_images[:train_sample_number]\n",
    "    test_sample = watermark_images[train_sample_number:]\n",
    "    # Return the training and testing samples of unrelated images\n",
    "    return train_sample, test_sample\n",
    "\n",
    "\n",
    "def watermark(train_images, train_labels, old_label, new_label, sample_rate, dataset: str, wtype='content'):\n",
    "    \"\"\"prepare the dataset for training to embed the watermark \n",
    "    \n",
    "    args:\n",
    "        train_images: clean training images\n",
    "        train_labels: clean training labels\n",
    "        old_label: label for watermarking\n",
    "        new_label: label after watermarking\n",
    "        sample_rate: sample rate for embedding the watermark\n",
    "        wtype: watermarking type ('content', 'noise', 'unrelated')\n",
    "    \n",
    "    return:\n",
    "        processed training and testing dataset for watermarking\n",
    "    \"\"\"\n",
    "    if wtype == 'unrelated':\n",
    "        train_sample, test_sample = get_unrelated_images(dataset, sample_rate)\n",
    "    else:\n",
    "        watermark_images = []\n",
    "        for i in range(len(train_labels)):\n",
    "            if train_labels[i] == old_label:\n",
    "                watermark_images.append(train_images[i])\n",
    "                \n",
    "        if wtype == 'content':\n",
    "            # add the trigger (size= 8*8) at the right bottom corner \n",
    "            mark_image = load_img('./mark/apple_black.png', color_mode='grayscale', target_size=(8, 8))\n",
    "            for i in range(len(watermark_images)):\n",
    "                image = array_to_img(watermark_images[i])\n",
    "                image.paste(mark_image, box=(image.size[0] - 8, image.size[1] - 8))\n",
    "                watermark_images[i] = img_to_array(image)\n",
    "        elif wtype == 'noise':\n",
    "            for i in range(len(watermark_images)):\n",
    "                image = random_noise(watermark_images[i] / 255.0, seed=1)\n",
    "                image = image * 255.0\n",
    "                watermark_images[i] = image\n",
    "                \n",
    "        random.shuffle(watermark_images)\n",
    "        watermark_images = np.array(watermark_images)\n",
    "        train_sample_number = int(len(watermark_images) * sample_rate)\n",
    "        train_sample = watermark_images[:train_sample_number]\n",
    "        test_sample = watermark_images[train_sample_number:]\n",
    "\n",
    "    if dataset == 'MNIST':\n",
    "        return train_sample, np.ones(train_sample.shape[0]) * new_label, test_sample, np.ones(\n",
    "            test_sample.shape[0]) * new_label\n",
    "    elif dataset == 'CIFAR10':\n",
    "        return train_sample, np.ones((train_sample.shape[0], 1)) * new_label, test_sample, np.ones((\n",
    "            test_sample.shape[0], 1)) * new_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b3ec97",
   "metadata": {},
   "source": [
    "## Training resnet v1 on CIFAR10 Dataset with black-box watermarking approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8837a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log saved at ./logs\n",
      "Using real-time data augmentation.\n",
      "Learning rate:  0.001\n",
      "Epoch 1/30\n",
      "781/781 [==============================] - 389s 484ms/step - loss: 1.6279 - accuracy: 0.4670 - val_loss: 1.3966 - val_accuracy: 0.5581 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 2/30\n",
      "781/781 [==============================] - 364s 466ms/step - loss: 1.2519 - accuracy: 0.6104 - val_loss: 1.2204 - val_accuracy: 0.6230 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 3/30\n",
      "781/781 [==============================] - 363s 464ms/step - loss: 1.0727 - accuracy: 0.6770 - val_loss: 1.2023 - val_accuracy: 0.6474 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 4/30\n",
      "781/781 [==============================] - 364s 466ms/step - loss: 0.9574 - accuracy: 0.7175 - val_loss: 1.0425 - val_accuracy: 0.6942 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 5/30\n",
      "781/781 [==============================] - 374s 479ms/step - loss: 0.8822 - accuracy: 0.7481 - val_loss: 0.9495 - val_accuracy: 0.7289 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 6/30\n",
      "781/781 [==============================] - 378s 484ms/step - loss: 0.8300 - accuracy: 0.7663 - val_loss: 0.9761 - val_accuracy: 0.7235 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 7/30\n",
      "781/781 [==============================] - 383s 490ms/step - loss: 0.7812 - accuracy: 0.7854 - val_loss: 0.9857 - val_accuracy: 0.7227 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 8/30\n",
      "781/781 [==============================] - 377s 482ms/step - loss: 0.7472 - accuracy: 0.7969 - val_loss: 0.9178 - val_accuracy: 0.7519 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 9/30\n",
      "781/781 [==============================] - 727s 932ms/step - loss: 0.7157 - accuracy: 0.8077 - val_loss: 1.0642 - val_accuracy: 0.7217 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 10/30\n",
      "781/781 [==============================] - 361s 462ms/step - loss: 0.6930 - accuracy: 0.8181 - val_loss: 0.7672 - val_accuracy: 0.7999 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 11/30\n",
      "781/781 [==============================] - 354s 453ms/step - loss: 0.6668 - accuracy: 0.8263 - val_loss: 0.8204 - val_accuracy: 0.7850 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 12/30\n",
      "781/781 [==============================] - 357s 457ms/step - loss: 0.6475 - accuracy: 0.8331 - val_loss: 0.8867 - val_accuracy: 0.7776 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 13/30\n",
      "781/781 [==============================] - 362s 463ms/step - loss: 0.6358 - accuracy: 0.8376 - val_loss: 0.8740 - val_accuracy: 0.7683 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 14/30\n",
      "781/781 [==============================] - 367s 470ms/step - loss: 0.6171 - accuracy: 0.8455 - val_loss: 0.7877 - val_accuracy: 0.7990 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 15/30\n",
      "781/781 [==============================] - 367s 470ms/step - loss: 0.6063 - accuracy: 0.8498 - val_loss: 0.7895 - val_accuracy: 0.7912 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 16/30\n",
      "781/781 [==============================] - 374s 478ms/step - loss: 0.5933 - accuracy: 0.8551 - val_loss: 1.0217 - val_accuracy: 0.7665 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 17/30\n",
      "781/781 [==============================] - 372s 476ms/step - loss: 0.5814 - accuracy: 0.8597 - val_loss: 0.9207 - val_accuracy: 0.7726 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 18/30\n",
      "781/781 [==============================] - 369s 472ms/step - loss: 0.5662 - accuracy: 0.8653 - val_loss: 0.7578 - val_accuracy: 0.8161 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 19/30\n",
      "781/781 [==============================] - 369s 472ms/step - loss: 0.5593 - accuracy: 0.8653 - val_loss: 0.8434 - val_accuracy: 0.7970 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 20/30\n",
      "781/781 [==============================] - 367s 470ms/step - loss: 0.5529 - accuracy: 0.8700 - val_loss: 0.8333 - val_accuracy: 0.7980 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 21/30\n",
      "781/781 [==============================] - 368s 471ms/step - loss: 0.5489 - accuracy: 0.8721 - val_loss: 1.0654 - val_accuracy: 0.7587 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 22/30\n",
      "781/781 [==============================] - 370s 474ms/step - loss: 0.5395 - accuracy: 0.8748 - val_loss: 0.7801 - val_accuracy: 0.8144 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 23/30\n",
      "781/781 [==============================] - 368s 472ms/step - loss: 0.5309 - accuracy: 0.8803 - val_loss: 0.7119 - val_accuracy: 0.8335 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 24/30\n",
      "781/781 [==============================] - 368s 471ms/step - loss: 0.5292 - accuracy: 0.8804 - val_loss: 0.9758 - val_accuracy: 0.7696 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 25/30\n",
      "781/781 [==============================] - 371s 475ms/step - loss: 0.5190 - accuracy: 0.8837 - val_loss: 0.7233 - val_accuracy: 0.8239 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 26/30\n",
      "781/781 [==============================] - 365s 468ms/step - loss: 0.5121 - accuracy: 0.8874 - val_loss: 0.7691 - val_accuracy: 0.8196 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 27/30\n",
      "781/781 [==============================] - 355s 455ms/step - loss: 0.5087 - accuracy: 0.8882 - val_loss: 0.7938 - val_accuracy: 0.8212 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 28/30\n",
      "781/781 [==============================] - 357s 457ms/step - loss: 0.5040 - accuracy: 0.8893 - val_loss: 0.8544 - val_accuracy: 0.8074 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 29/30\n",
      "781/781 [==============================] - 358s 458ms/step - loss: 0.5027 - accuracy: 0.8918 - val_loss: 0.9015 - val_accuracy: 0.7914 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 30/30\n",
      "781/781 [==============================] - 362s 464ms/step - loss: 0.4962 - accuracy: 0.8940 - val_loss: 0.8225 - val_accuracy: 0.8191 - lr: 0.0010\n",
      "313/313 [==============================] - 13s 41ms/step - loss: 0.8225 - accuracy: 0.8191\n",
      "Non-Watermarked Model Testing Accuracy:  0.819100022315979\n",
      "Non-Watermarked Model Testing Loss:  0.8224585056304932\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':    \n",
    "    #wtype = 'content'\n",
    "    dataset = 'CIFAR10'\n",
    "    training_nums = 25000 \n",
    "    batch_size = 64\n",
    "    epochs = 30 # 80 for cifar10 and 10 for mnist\n",
    "    no_augmentation = False\n",
    "    old_label = 1\n",
    "    new_label = 3\n",
    "    log_dir = './logs' \n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "    print('log saved at ' + log_dir)\n",
    "    \n",
    "    \n",
    "    training_images, training_labels, test_images, test_labels = load_data(dataset)\n",
    "    #train_sample_images, train_sample_labels, test_sample_images, test_sample_labels = watermark(training_images,\n",
    "#                                                                                                  training_labels, old_label, new_label,\n",
    "#                                                                                                  0.1, dataset,\n",
    "#                                                                                                  wtype=wtype)\n",
    "\n",
    "    training_labels = tf.keras.utils.to_categorical(training_labels, 10)\n",
    "    test_labels = tf.keras.utils.to_categorical(test_labels, 10)\n",
    "    #train_sample_labels = tf.keras.utils.to_categorical(train_sample_labels, 10)\n",
    "    #test_sample_labels = tf.keras.utils.to_categorical(test_sample_labels, 10)\n",
    "\n",
    "    training_images = training_images / 255.0\n",
    "    test_images = test_images / 255.0\n",
    "    #train_sample_images = train_sample_images / 255.0\n",
    "    #test_sample_images = test_sample_images / 255.0\n",
    "    #training_all_images = np.concatenate((training_images[:training_nums], train_sample_images), axis=0)\n",
    "    #training_all_labels = np.concatenate((training_labels[:training_nums], train_sample_labels), axis=0)\n",
    "    \n",
    "    # This line sets the input shape of the model to the shape of the training images excluding the number of samples in the first dimension.\n",
    "    input_shape = training_images.shape[1:]\n",
    "    # This line creates a ResNet v1 model with a depth of 20 and the specified input shape.\n",
    "    model = resnet_v1(input_shape=input_shape, depth=20) \n",
    "    #This line prints a summary of the model to the console using the specified log function.\n",
    "    model.summary(print_fn=log)\n",
    "    #This line creates a learning rate scheduler that reduces the learning rate over time according to the specified function.\n",
    "    reduce_lr = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "    # This line creates a learning rate reducer that reduces the learning rate by a factor of 0.1 when a metric has stopped improving.\n",
    "    lr_reducer = tf.keras.callbacks.ReduceLROnPlateau(factor=np.sqrt(0.1),cooldown=0,patience=5,min_lr=0.5e-6)\n",
    "    # This line compiles the model with the Adam optimizer, categorical cross-entropy loss, and accuracy metric.\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    if no_augmentation:\n",
    "        print('Not using data augmentation.')\n",
    "        history = model.fit(training_images, training_labels,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=epochs,\n",
    "                            validation_data=(test_images, test_labels),\n",
    "                            callbacks=[reduce_lr, lr_reducer])\n",
    "    else:\n",
    "        print('Using real-time data augmentation.')\n",
    "        # # This line creates an image data generator with the specified augmentation parameters.\n",
    "        data_gen = ImageDataGenerator(\n",
    "            rotation_range=10,\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1\n",
    "        )\n",
    "        #  This line fits the model to the augmented data using the data generator, the specified number of epochs, and the specified validation data.\n",
    "        history = model.fit(data_gen.flow(training_images, training_labels, batch_size=batch_size),\n",
    "                            epochs=epochs,\n",
    "                            validation_data=(test_images, test_labels),\n",
    "                            callbacks=[reduce_lr, lr_reducer],\n",
    "                            steps_per_epoch=training_images.shape[0] // batch_size)\n",
    "    #This line saves the training history of the model as a CSV file in the specified directory.\n",
    "    pd.DataFrame(history.history).to_csv(log_dir + '/log.csv')\n",
    "    \n",
    "    if log_dir is not None:\n",
    "        model.save(log_dir + '/non-watermarked_model.h5')\n",
    "        #np.savez(log_dir + \"/content_trigger.npz\", test_sample_images=test_sample_images, test_sample_labels=test_sample_labels)\n",
    "        \n",
    "    loss, TSA = model.evaluate(test_images, test_labels)\n",
    "    print('Non-Watermarked Model Testing Accuracy: ', TSA)\n",
    "    print('Non-Watermarked Model Testing Loss: ', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bafad63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log saved at ./logs\n",
      "Using real-time data augmentation.\n",
      "Learning rate:  0.001\n",
      "Epoch 1/30\n",
      "398/398 [==============================] - 205s 490ms/step - loss: 1.7685 - accuracy: 0.4185 - val_loss: 1.6510 - val_accuracy: 0.4702 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 2/30\n",
      "398/398 [==============================] - 194s 487ms/step - loss: 1.4157 - accuracy: 0.5474 - val_loss: 1.5733 - val_accuracy: 0.5024 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 3/30\n",
      "398/398 [==============================] - 194s 487ms/step - loss: 1.2470 - accuracy: 0.6137 - val_loss: 1.1859 - val_accuracy: 0.6367 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 4/30\n",
      "398/398 [==============================] - 197s 494ms/step - loss: 1.1361 - accuracy: 0.6524 - val_loss: 1.8023 - val_accuracy: 0.4934 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 5/30\n",
      "398/398 [==============================] - 194s 487ms/step - loss: 1.0658 - accuracy: 0.6771 - val_loss: 1.2266 - val_accuracy: 0.6359 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 6/30\n",
      "398/398 [==============================] - 193s 485ms/step - loss: 0.9965 - accuracy: 0.7028 - val_loss: 1.4002 - val_accuracy: 0.6090 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 7/30\n",
      "398/398 [==============================] - 195s 490ms/step - loss: 0.9434 - accuracy: 0.7244 - val_loss: 1.3197 - val_accuracy: 0.6408 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 8/30\n",
      "398/398 [==============================] - 196s 492ms/step - loss: 0.8979 - accuracy: 0.7397 - val_loss: 1.0941 - val_accuracy: 0.6854 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 9/30\n",
      "398/398 [==============================] - 234s 587ms/step - loss: 0.8631 - accuracy: 0.7527 - val_loss: 1.6561 - val_accuracy: 0.5970 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 10/30\n",
      "398/398 [==============================] - 263s 661ms/step - loss: 0.8229 - accuracy: 0.7672 - val_loss: 0.9375 - val_accuracy: 0.7431 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 11/30\n",
      "398/398 [==============================] - 261s 655ms/step - loss: 0.7957 - accuracy: 0.7771 - val_loss: 1.1361 - val_accuracy: 0.6829 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 12/30\n",
      "398/398 [==============================] - 261s 655ms/step - loss: 0.7584 - accuracy: 0.7933 - val_loss: 0.9837 - val_accuracy: 0.7324 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 13/30\n",
      "398/398 [==============================] - 261s 657ms/step - loss: 0.7437 - accuracy: 0.7960 - val_loss: 1.0598 - val_accuracy: 0.7197 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 14/30\n",
      "398/398 [==============================] - 261s 655ms/step - loss: 0.7157 - accuracy: 0.8087 - val_loss: 1.0935 - val_accuracy: 0.6989 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 15/30\n",
      "398/398 [==============================] - 263s 660ms/step - loss: 0.6945 - accuracy: 0.8138 - val_loss: 1.0876 - val_accuracy: 0.7075 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 16/30\n",
      "398/398 [==============================] - 267s 670ms/step - loss: 0.6721 - accuracy: 0.8262 - val_loss: 0.9742 - val_accuracy: 0.7439 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 17/30\n",
      "398/398 [==============================] - 269s 675ms/step - loss: 0.6523 - accuracy: 0.8308 - val_loss: 0.9652 - val_accuracy: 0.7439 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 18/30\n",
      "398/398 [==============================] - 259s 651ms/step - loss: 0.6464 - accuracy: 0.8326 - val_loss: 1.0742 - val_accuracy: 0.7263 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 19/30\n",
      "398/398 [==============================] - 262s 657ms/step - loss: 0.6188 - accuracy: 0.8438 - val_loss: 1.1102 - val_accuracy: 0.7213 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 20/30\n",
      "398/398 [==============================] - 265s 666ms/step - loss: 0.6126 - accuracy: 0.8485 - val_loss: 1.0562 - val_accuracy: 0.7269 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 21/30\n",
      "398/398 [==============================] - 263s 660ms/step - loss: 0.5924 - accuracy: 0.8535 - val_loss: 1.1276 - val_accuracy: 0.7251 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 22/30\n",
      "398/398 [==============================] - 259s 650ms/step - loss: 0.5870 - accuracy: 0.8572 - val_loss: 1.1497 - val_accuracy: 0.7173 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 23/30\n",
      "398/398 [==============================] - 260s 652ms/step - loss: 0.5733 - accuracy: 0.8597 - val_loss: 0.9960 - val_accuracy: 0.7546 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 24/30\n",
      "398/398 [==============================] - 243s 611ms/step - loss: 0.5641 - accuracy: 0.8662 - val_loss: 0.8951 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 25/30\n",
      "398/398 [==============================] - 182s 458ms/step - loss: 0.5594 - accuracy: 0.8670 - val_loss: 0.9458 - val_accuracy: 0.7641 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 26/30\n",
      "398/398 [==============================] - 189s 474ms/step - loss: 0.5474 - accuracy: 0.8724 - val_loss: 0.9095 - val_accuracy: 0.7808 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 27/30\n",
      "398/398 [==============================] - 187s 469ms/step - loss: 0.5271 - accuracy: 0.8812 - val_loss: 0.9585 - val_accuracy: 0.7758 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 28/30\n",
      "398/398 [==============================] - 188s 471ms/step - loss: 0.5338 - accuracy: 0.8766 - val_loss: 0.8742 - val_accuracy: 0.7914 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 29/30\n",
      "398/398 [==============================] - 188s 473ms/step - loss: 0.5150 - accuracy: 0.8859 - val_loss: 1.1728 - val_accuracy: 0.7390 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 30/30\n",
      "398/398 [==============================] - 191s 479ms/step - loss: 0.5072 - accuracy: 0.8885 - val_loss: 1.0343 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "141/141 [==============================] - 6s 40ms/step - loss: 0.1937 - accuracy: 1.0000\n",
      "Watermarked Model Testing Accuracy:  1.0\n",
      "Watermarked Model Testing Loss:  0.19373130798339844\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':    \n",
    "    wtype = 'content'\n",
    "    dataset = 'CIFAR10'\n",
    "    training_nums = 25000 \n",
    "    batch_size = 64\n",
    "    epochs = 30 # 80 for cifar10 and 10 for mnist\n",
    "    no_augmentation = False\n",
    "    old_label = 1\n",
    "    new_label = 3\n",
    "    log_dir = './logs' \n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "    print('log saved at ' + log_dir)\n",
    "    \n",
    "    \n",
    "    training_images, training_labels, test_images, test_labels = load_data(dataset)\n",
    "    train_sample_images, train_sample_labels, test_sample_images, test_sample_labels = watermark(training_images,\n",
    "                                                                                                 training_labels, old_label, new_label,\n",
    "                                                                                                 0.1, dataset,\n",
    "                                                                                                 wtype=wtype)\n",
    "\n",
    "    training_labels = tf.keras.utils.to_categorical(training_labels, 10)\n",
    "    test_labels = tf.keras.utils.to_categorical(test_labels, 10)\n",
    "    train_sample_labels = tf.keras.utils.to_categorical(train_sample_labels, 10)\n",
    "    test_sample_labels = tf.keras.utils.to_categorical(test_sample_labels, 10)\n",
    "\n",
    "    training_images = training_images / 255.0\n",
    "    test_images = test_images / 255.0\n",
    "    train_sample_images = train_sample_images / 255.0\n",
    "    test_sample_images = test_sample_images / 255.0\n",
    "    training_all_images = np.concatenate((training_images[:training_nums], train_sample_images), axis=0)\n",
    "    training_all_labels = np.concatenate((training_labels[:training_nums], train_sample_labels), axis=0)\n",
    "    \n",
    "    input_shape = training_images.shape[1:]\n",
    "    model = resnet_v1(input_shape=input_shape, depth=20) \n",
    "    model.summary(print_fn=log)\n",
    "    \n",
    "    reduce_lr = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "    lr_reducer = tf.keras.callbacks.ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                                                      cooldown=0,\n",
    "                                                      patience=5,\n",
    "                                                      min_lr=0.5e-6)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    if no_augmentation:\n",
    "        print('Not using data augmentation.')\n",
    "        history0 = model.fit(training_all_images, training_all_labels,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=epochs,\n",
    "                            validation_data=(test_images, test_labels),\n",
    "                            callbacks=[reduce_lr, lr_reducer])\n",
    "    else:\n",
    "        print('Using real-time data augmentation.')\n",
    "        data_gen = ImageDataGenerator(\n",
    "            rotation_range=10,\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1\n",
    "        )\n",
    "        history0 = model.fit(data_gen.flow(training_all_images, training_all_labels, batch_size=batch_size),\n",
    "                            epochs=epochs,\n",
    "                            validation_data=(test_images, test_labels),\n",
    "                            callbacks=[reduce_lr, lr_reducer],\n",
    "                            steps_per_epoch=training_all_images.shape[0] // batch_size)\n",
    "\n",
    "    pd.DataFrame(history.history).to_csv(log_dir + '/log.csv')\n",
    "    \n",
    "    if log_dir is not None:\n",
    "        model.save(log_dir + '/watermarked_model.h5')\n",
    "        np.savez(log_dir + \"/content_trigger.npz\", test_sample_images=test_sample_images, test_sample_labels=test_sample_labels)\n",
    "        \n",
    "    loss, TSA = model.evaluate(test_sample_images, test_sample_labels)\n",
    "    print('Watermarked Model Testing Accuracy: ', TSA)\n",
    "    print('Watermarked Model Testing Loss: ', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "057b4ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "wtype = 'content'\n",
    "dataset = 'CIFAR10'\n",
    "old_label = 1\n",
    "new_label = 3\n",
    "training_images, training_labels, test_images, test_labels = load_data(dataset)\n",
    "train_sample_images, train_sample_labels, test_sample_images, test_sample_labels = watermark(training_images,\n",
    "                                                                                                 training_labels, old_label, new_label,\n",
    "                                                                                                 0.1, dataset,\n",
    "                                                                                                 wtype=wtype)\n",
    "\n",
    "train_sample_labels = tf.keras.utils.to_categorical(train_sample_labels, 10)\n",
    "test_sample_labels = tf.keras.utils.to_categorical(test_sample_labels, 10)\n",
    "train_sample_images = train_sample_images / 255.0\n",
    "test_sample_images = test_sample_images / 255.0\n",
    "\n",
    "# loading watermarked model \n",
    "model_wm = tf.keras.models.load_model('logs/watermarked_model.h5')\n",
    "\n",
    "# loading non-watermarked model \n",
    "model = tf.keras.models.load_model('logs/non-watermarked_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "077a66e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label of selected image:  1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = train_sample_images[0]\n",
    "label = train_sample_labels[0]\n",
    "print(\"label of selected image: \",label.max())\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8d9505d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 829ms/step\n",
      "1/1 [==============================] - 1s 538ms/step\n",
      "The models made different predictions.\n",
      "Original Label:  1.0\n",
      "Watermarked Model  predicted class: 3, confidence: 1.0\n",
      "Non Watermarked Model predicted class: 1, confidence: 0.9990729093551636\n"
     ]
    }
   ],
   "source": [
    "img = np.expand_dims(img, axis=0)\n",
    "#watermarked model\n",
    "pred_wm = model_wm.predict(img)\n",
    "#non watermarked model\n",
    "pred = model.predict(img)\n",
    "\n",
    "# Compare the predicted classes\n",
    "predicted_class1 = pred_wm.argmax()\n",
    "predicted_class2 = pred.argmax()\n",
    "\n",
    "if predicted_class1 == predicted_class2:\n",
    "    print(\"The models made the same prediction.\")\n",
    "else:\n",
    "    print(\"The models made different predictions.\")\n",
    "    \n",
    "# Print the predicted class and confidence for each model\n",
    "confidence1 = pred_wm.max()\n",
    "confidence2 = pred.max()\n",
    "print(\"Original Label: \",label.max())\n",
    "print(f\"Watermarked Model  predicted class: {predicted_class1}, confidence: {confidence1}\")\n",
    "print(f\"Non Watermarked Model predicted class: {predicted_class2}, confidence: {confidence2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f402c8",
   "metadata": {},
   "source": [
    "# Steganography within Neural Network Architecture\n",
    "\n",
    "This notebook aims to explore the potential of steganography using neural network layers. The primary objective is to examine the feasibility of hiding sensitive information, such as text, images, videos, or software, within the parameters of a neural network model.\n",
    "\n",
    "The idea is to leverage the inherent complexity and non-linearity of the neural network layers to encode the secret data and obscure it from unauthorized access. By embedding the secret data in the model's parameters, it can potentially bypass traditional security measures such as encryption, making it a promising technique for secure communication.\n",
    "\n",
    "The notebook will also investigate how this technique impacts the model's performance, including factors such as accuracy, speed, and computational resources required. The results of this experiment will provide insights into the trade-offs between the level of secrecy achieved and the impact on the model's performance.\n",
    "\n",
    "It is worth noting that this is a proof-of-concept experiment and should not be used for any illegal or unethical purposes. The goal is to explore the possibilities and limitations of steganography with neural network layers and contribute to the advancement of secure communication methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55748a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many bits (LSB) to use from the fraction (mantissa) of the float values\n",
    "BITS_TO_USE = 16\n",
    "assert BITS_TO_USE <= 23, \"Can't be bigger then 23 bits\"\n",
    "\n",
    "DATA_FOLDER = \"data\"\n",
    "\n",
    "IMAGES_TO_TEST_ON = list(map(str, Path(DATA_FOLDER).glob(\"**/*.jpg\")))\n",
    "assert len(IMAGES_TO_TEST_ON) > 0, \"You'll need some images to test the network performance\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e36fc2",
   "metadata": {},
   "source": [
    "## Load the watermarked model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c95af81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any model can be used here\n",
    "model = tf.keras.models.load_model('logs/watermarked_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31884d2d",
   "metadata": {},
   "source": [
    "## Data storage capacity of the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41e1a1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create an empty dictionary to store the storage capacity of each layer in megabytes\n",
    "layers_storage_capacity_mb: Dict[str, int] = {}\n",
    "# Loop over each layer in the model\n",
    "for l in model.layers:\n",
    "    # # Check if the layer is a Conv2D layer\n",
    "    if l.__class__.__name__ == \"Conv2D\":\n",
    "        # # Calculate the number of parameters in the layer and convert it to bytes\n",
    "        nb_params = np.prod(l.get_weights()[0].shape)\n",
    "        capacity_in_bytes = np.floor((nb_params * BITS_TO_USE) / 8).astype(int)\n",
    "        # # Store the storage capacity of the layer in megabytes in the dictionary\n",
    "        layers_storage_capacity_mb[l.name] = capacity_in_bytes / float(1<<20)\n",
    "# Create a bar plot of the storage capacity of each layer in the model        \n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 4))\n",
    "ax.bar(layers_storage_capacity_mb.keys(), layers_storage_capacity_mb.values())\n",
    "ax.tick_params(axis='x', labelrotation = 90)\n",
    "ax.set_xlabel(\"Layer Name\")\n",
    "ax.set_ylabel(\"Megabytes\")\n",
    "ax.set_title(f\"Storage capacity when using {BITS_TO_USE} bits from every float value\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078de9f5",
   "metadata": {},
   "source": [
    "## Inspect statistics for selected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cdc923c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layers with the most storage capacity\n",
    "# sorted(layers_storage_capacity_mb.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "\n",
    "# These layers will be modified to hide the secret\n",
    "\n",
    "# Selected layers (manual selection)\n",
    "# layer_names = [\"conv5_block1_2_conv\", \"conv5_block2_2_conv\", \"conv5_block3_2_conv\"]\n",
    "\n",
    "# All the Conv2D layers\n",
    "layer_names = list(layers_storage_capacity_mb.keys())\n",
    "# initialize an empty list to store the weights of selected layers\n",
    "selected_layers_weights = []\n",
    "# loop through each layer name in the model\n",
    "for n in layer_names:\n",
    "    # get the weight tensor of the layer as a numpy array and flatten it into a 1D array\n",
    "    v = model.get_layer(n).weights[0].numpy().ravel()\n",
    "    # extend the selected_layers_weights list with the flattened weight array of the current layer\n",
    "    selected_layers_weights.extend(v)\n",
    "# convert the selected_layers_weights list to a numpy array\n",
    "selected_layers_weights = np.array(selected_layers_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2198ac",
   "metadata": {},
   "source": [
    "## Basic statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3651fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats for ['conv2d_42', 'conv2d_43', 'conv2d_44', 'conv2d_45', 'conv2d_46', 'conv2d_47', 'conv2d_48', 'conv2d_49', 'conv2d_50', 'conv2d_51', 'conv2d_52', 'conv2d_53', 'conv2d_54', 'conv2d_55', 'conv2d_56', 'conv2d_57', 'conv2d_58', 'conv2d_59', 'conv2d_60', 'conv2d_61', 'conv2d_62']\n",
      "---\n",
      "Min: -0.6514785885810852\n",
      "Abs. Min 4.172616172581911e-07\n",
      "Max: 0.666040301322937\n",
      "Mean: -0.004356221295893192\n",
      "---\n",
      "Nb total values: 270256\n",
      "Nb values < 10e-4: 2652 - 0.9813%\n",
      "Nb values < 10e-3: 27008 - 9.9935%\n",
      "Nb negatives: 141966 - 52.5302%\n",
      "Nb positives: 128290 - 47.4698%\n",
      "---\n",
      "(Maximum) Storage capacity is 0.0 MB for the 21 layers with the 16 bits modification\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count the number of values in the selected_layers_weights\n",
    "nb_values = len(selected_layers_weights)\n",
    "# Get the minimum value in the selected_layers_weights\n",
    "min_value = selected_layers_weights.min()\n",
    "# Get the absolute minimum value in the selected_layers_weights\n",
    "abs_min_value = np.abs(selected_layers_weights).min()\n",
    "# Get the maximum value in the selected_layers_weights\n",
    "max_value = selected_layers_weights.max()\n",
    "# Calculate the mean of the values in the selected_layers_weights\n",
    "mean_value = selected_layers_weights.mean()\n",
    "# Count the number of values in the selected_layers_weights that are less than 10e-4 (very small values)\n",
    "nb_really_small_values = (abs(selected_layers_weights) < 10e-4).sum()\n",
    "# Count the number of values in the selected_layers_weights that are less than 10e-3 (small values)\n",
    "nb_small_values = (abs(selected_layers_weights) < 10e-3).sum()\n",
    "# Count the number of negative values in the selected_layers_weights\n",
    "nb_negative_values = (selected_layers_weights < 0).sum()\n",
    "# Count the number of positive values in the selected_layers_weights\n",
    "nb_positive_values = (selected_layers_weights > 0).sum()\n",
    "# Calculate the overall storage capacity of the selected_layers_weights in bytes and megabytes\n",
    "overall_storage_capacity_bytes = nb_values * BITS_TO_USE / 8\n",
    "overall_storage_capacity_mb = overall_storage_capacity_bytes // float(1<<20)\n",
    "# Print out the statistics and information for the selected_layers_weights\n",
    "print(f\"\"\"Stats for {layer_names}\n",
    "---\n",
    "Min: {min_value}\n",
    "Abs. Min {abs_min_value}\n",
    "Max: {max_value}\n",
    "Mean: {mean_value}\n",
    "---\n",
    "Nb total values: {nb_values}\n",
    "Nb values < 10e-4: {nb_really_small_values} - {nb_really_small_values/nb_values*100:.4f}%\n",
    "Nb values < 10e-3: {nb_small_values} - {nb_small_values/nb_values*100:.4f}%\n",
    "Nb negatives: {nb_negative_values} - {nb_negative_values/nb_values*100:.4f}%\n",
    "Nb positives: {nb_positive_values} - {nb_positive_values/nb_values*100:.4f}%\n",
    "---\n",
    "(Maximum) Storage capacity is {overall_storage_capacity_mb} MB for the {len(layer_names)} layers with the {BITS_TO_USE} bits modification\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756b2e6c",
   "metadata": {},
   "source": [
    "## Hide a secret in the layer\n",
    "\n",
    "### The secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7dff87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We need 23 float values to store the info\n",
      "Overall number of values we could use: 270256\n"
     ]
    }
   ],
   "source": [
    "# Define a string variable containing the secret message to be hidden\n",
    "secret_to_hide = \"I am Rex and I would like to hide this message\"\n",
    "# Generate dummy data for overall storage capacity in bytes (this line is currently commented out)\n",
    "#secret_to_hide = dummy_data_generator.generate_dummy_data(overall_storage_capacity_bytes)\n",
    "# Convert the secret message string into a sequence of binary bits\n",
    "secret_bits = str_to_bits(secret_to_hide)\n",
    "# Calculate the number of floating point values needed to store the secret message\n",
    "nb_vals_needed = math.ceil(len(secret_bits) / BITS_TO_USE)\n",
    "# Print the number of floating point values needed to store the secret message, as well as the overall number of values that could be used for storage\n",
    "print(f\"We need {nb_vals_needed} float values to store the info\\nOverall number of values we could use: {nb_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2add5c53",
   "metadata": {},
   "source": [
    "### Hide it\n",
    "\n",
    "#### Store the original weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "00973e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dict variable is created to hold the original weights for the selected layers\n",
    "original_weights_dict: dict = {}\n",
    "# Iterate through the list of layer names to get their original weights and store them in the dictionary\n",
    "for n in layer_names:\n",
    "    # model.get_layer(n).weights returns the trainable weights of the given layer as a list of weight tensors\n",
    "    # model.get_layer(n).weights[0] returns the first weight tensor of the given layer, which corresponds to the kernel\n",
    "    # model.get_layer(n).weights[0].numpy() returns the values of the kernel as a numpy array\n",
    "    # deepcopy() is used to create a new object with a copy of the original weight values, to avoid modifying the original\n",
    "    original_weights_dict[n] = deepcopy(model.get_layer(n).weights[0].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02741759",
   "metadata": {},
   "source": [
    "#### Create the modified ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "affbf130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer conv2d_42 is processed, last index modified: 22\n"
     ]
    }
   ],
   "source": [
    "# This dict will hold the modified (secret hidden) weights for the layers\n",
    "modified_weights_dict = deepcopy(original_weights_dict)\n",
    "# Index of the last value used in a layer - this is needed because we don't necessary need\n",
    "# the same number of params for hiding some bits then all the layer parameters\n",
    "last_index_used_in_layer_dict: dict = {}\n",
    "\n",
    "# We are modifying the layers in a defined order to know what was changed exactly\n",
    "# This order is needed when we would like to recover the message\n",
    "\n",
    "# Variable which tracks the number of values changed so far (used to index the secret message bits)\n",
    "i = 0\n",
    "# This loop iterates over the layer names\n",
    "for n in layer_names:\n",
    "    # Check if we need more values to use to hide the secret, if not then we are done with modifying the layer's weights\n",
    "    if i >= nb_vals_needed:\n",
    "        break\n",
    "    # Get the weights of the current layer and its shape, then flatten the weights\n",
    "    w = modified_weights_dict[n]\n",
    "    w_shape = w.shape\n",
    "    w = w.ravel()\n",
    "    # Calculate the number of parameters in the layer\n",
    "    nb_params_in_layer: int = np.prod(w.shape)\n",
    "    # Loop over each parameter in the layer and hide secret bits in them\n",
    "    for j in range(nb_params_in_layer):\n",
    "        # Calculate the range of bits to hide in the current parameter\n",
    "        _from_index = i * BITS_TO_USE\n",
    "        _to_index = _from_index + BITS_TO_USE\n",
    "        bits_to_hide = secret_bits[_from_index:_to_index]\n",
    "        bits_to_hide = list(map(bool, bits_to_hide))\n",
    "\n",
    "        # Modify the fraction of the floating-point value of the parameter using the defined bits of the secret\n",
    "        x = FloatBinary(w[j])\n",
    "        fraction_modified = list(x.fraction)\n",
    "        if len(bits_to_hide) > 0:\n",
    "            fraction_modified[-BITS_TO_USE:] = bits_to_hide\n",
    "\n",
    "        x_modified = x.modify_clone(fraction=tuple(fraction_modified))\n",
    "        w[j] = x_modified.v\n",
    "        # Increment the number of values used to hide the secret\n",
    "        i += 1\n",
    "        \n",
    "        # Check if we need more values to use to hide the secret in the current layer, if not then we are done\n",
    "        if i >= nb_vals_needed:\n",
    "            break\n",
    "    # Record the index of the last parameter used to hide the secret in the current layer\n",
    "    last_index_used_in_layer_dict[n] = j\n",
    "    # Reshape the modified weights to their original shape and update the modified weights dictionary\n",
    "    w = w.reshape(w_shape)\n",
    "    modified_weights_dict[n] = w\n",
    "    # Print a message indicating the current layer is processed and the index of the last modified parameter\n",
    "    print(f\"Layer {n} is processed, last index modified: {j}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42a6d42",
   "metadata": {},
   "source": [
    "## Let's test the network and inspect the outputs\n",
    "\n",
    "### Dataset to test on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "463a2632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images will be used for testing: 4\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of images will be used for testing: {len(IMAGES_TO_TEST_ON)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65c81958",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "# Define a function to read an image from a given file path\n",
    "def _read_image_from_path(image_path):\n",
    "    ## Read image file\n",
    "    image = tf.io.read_file(image_path)\n",
    "    # Decode image into a 3-channel uint8 tensor, ignoring any animation frames\n",
    "    image = tf.image.decode_image(image, channels=3, dtype=tf.uint8, expand_animations=False)\n",
    "    # Resize image to 32x32 pixels\n",
    "    image = tf.image.resize(image, (32, 32))\n",
    "    return image\n",
    "# Create a dataset of file paths to the images we want to test on\n",
    "dataset = tf.data.Dataset.from_tensor_slices(IMAGES_TO_TEST_ON)\n",
    "# Map the _read_image_from_path function onto each element in the dataset, using AUTOTUNE to parallelize processing\n",
    "dataset = dataset.map(_read_image_from_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# Batch the dataset into groups of 8 images, prefetching data to minimize data loading time\n",
    "dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381538a1",
   "metadata": {},
   "source": [
    "## Predictions made by the model\n",
    "\n",
    "### Original weights predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "41146cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original weights to the model layers\n",
    "for n in layer_names:\n",
    "    w = original_weights_dict[n]\n",
    "    model.get_layer(n).set_weights([w, model.get_layer(n).get_weights()[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2493f4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 560ms/step\n"
     ]
    }
   ],
   "source": [
    "preds_original = model.predict(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f91a91b",
   "metadata": {},
   "source": [
    "### Modified weights predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2075d974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the modified (secret is hidden) weights to the model layers\n",
    "for n in layer_names:\n",
    "    w = modified_weights_dict[n]\n",
    "    model.get_layer(n).set_weights([w, model.get_layer(n).get_weights()[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8540fbf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    }
   ],
   "source": [
    "preds_modified = model.predict(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2372871",
   "metadata": {},
   "source": [
    "## Differences in predictions\n",
    "\n",
    "### Raw prediction value comparisons (last layer output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9a3aafb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate the absolute difference between predictions of two models and convert them to a 1-D array\n",
    "diff_abs = np.abs(preds_original - preds_modified).ravel()\n",
    "# Plot a histogram of absolute differences that are greater than or equal to zero\n",
    "plt.hist(diff_abs[diff_abs >= 0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "876ed1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min abs difference: 0.0\n",
      "Max abs difference: 0.0\n",
      "Number of changed prediction values: 0 / 40 | 0.0000%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Min abs difference: {diff_abs.min()}\")\n",
    "print(f\"Max abs difference: {diff_abs.max()}\")\n",
    "print(f\"Number of changed prediction values: {(diff_abs > 0).sum()} / {len(diff_abs)} | {(diff_abs > 0).sum()/len(diff_abs)*100:.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2df9b1",
   "metadata": {},
   "source": [
    "### Change in predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5f517016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed number of predictions: 0 / 4 | 0.0%\n"
     ]
    }
   ],
   "source": [
    "nb_changed_pred_labels = ((np.argmax(preds_original, 1) - np.argmax(preds_modified, 1)) > 0).sum()\n",
    "\n",
    "print(f\"Changed number of predictions: {nb_changed_pred_labels} / {len(IMAGES_TO_TEST_ON)} | {nb_changed_pred_labels / len(IMAGES_TO_TEST_ON)*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887515b3",
   "metadata": {},
   "source": [
    "### Recover the secret\n",
    "For recovering the secret we only need to know the layer names/indices in the model and the bits which we used for the \"encoding\".\n",
    "\n",
    "(And of course in a real life scenario we need direct access to the model's weights 😉)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "88983579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer conv2d_42 is processed, bits are extracted\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to store the extracted bits of data\n",
    "hidden_data: List[bool] = []\n",
    "# Loop through each layer in the model and check if it was used to hide the secret\n",
    "for n in layer_names:\n",
    "    # If the layer was not used, skip it and continue to the next one\n",
    "    if n not in last_index_used_in_layer_dict.keys():\n",
    "        continue\n",
    "    \n",
    "   # Get the modified weights for the layer and reshape them into a 1D array\n",
    "    w = modified_weights_dict[n]\n",
    "    w_shape = w.shape\n",
    "    w = w.ravel()\n",
    "    # Calculate the number of parameters in the layer\n",
    "    nb_params_in_layer: int = np.prod(w.shape)\n",
    "    # Loop through the first few weights in the layer and extract the hidden bits from them\n",
    "    for i in range(last_index_used_in_layer_dict[n]+1):\n",
    "        x = FloatBinary(w[i])\n",
    "        hidden_bits = x.fraction[-BITS_TO_USE:]\n",
    "        hidden_data.extend(hidden_bits)\n",
    "    # Print a message indicating that the layer has been processed and its bits have been extracted    \n",
    "    print(f\"Layer {n} is processed, bits are extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "08ec773a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Original string:--\n",
      "'I am Rex and I would like to hide this message...'\n",
      "--Recovered string:--\n",
      "'I am Rex and I would like to hide this message...'\n"
     ]
    }
   ],
   "source": [
    "# The following line decodes the hidden data, which is a list of bits, into a string.\n",
    "recovered_message: str = bits_to_str(list(map(int, hidden_data)))\n",
    "# This line sets a variable \"chars_to_display\" to 100, which is the number of characters from the beginning of the strings that will be displayed. \n",
    "chars_to_display = 100\n",
    "# This line prints the original message to the console, only displaying the first \"chars_to_display\" characters, followed by ellipsis.\n",
    "print(f\"--Original string:--\\n'{secret_to_hide[:chars_to_display]}...'\")\n",
    "# This line prints the recovered message to the console, only displaying the first \"chars_to_display\" characters, followed by ellipsis.\n",
    "print(f\"--Recovered string:--\\n'{recovered_message[:chars_to_display]}...'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7d8bf06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful secret hiding and recovery! 🥳\n"
     ]
    }
   ],
   "source": [
    "# Define a function that takes a string as input and returns its MD5 hash value as a string.\n",
    "def hash_str(s: str) -> str:\n",
    "    return hashlib.md5(s.encode(\"ascii\")).hexdigest()\n",
    "# Check if the MD5 hash value of the recovered message is the same as the MD5 hash value of the secret message.\n",
    "# If they match, print a success message.\n",
    "# Otherwise, print a message indicating that the recovered message is not the same as the original one.\n",
    "if hash_str(recovered_message) == hash_str(secret_to_hide):\n",
    "    print(\"Successful secret hiding and recovery! 🥳\")\n",
    "else:\n",
    "    print(\"Recovered message is not the same as the original one 🤨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb829cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b3545c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8da0696",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27c7a7e7",
   "metadata": {},
   "source": [
    "# Hybrid Approach for Watermarking Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63435dc",
   "metadata": {},
   "source": [
    "## Following section embeds watermarks into a resnet architecture using black box watermarking approach. The dataset used is CIFAR10.\n",
    "\n",
    "### Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bded2210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c4ff853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25962578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install matplotlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25464da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip\n",
    "# !pip install resnet20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ebb2c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e546782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from platform import python_version\n",
    "# print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da486797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img, array_to_img, ImageDataGenerator\n",
    "import gzip\n",
    "from skimage.util.noise import random_noise\n",
    "from resnet20 import resnet_v1\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from tensorflow.keras.layers import AveragePooling2D, Input, Flatten\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import math\n",
    "from typing import List, Tuple, Dict\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "import hashlib\n",
    "import concurrent.futures\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "\n",
    "from stego import FloatBinary, str_to_bits, bits_to_str, dummy_data_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11d7752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line sets the environment variable CUDA_VISIBLE_DEVICES to '0' which specifies that only the first GPU is visible to the script.\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'\n",
    "#This line lists the available physical GPUs in the system.\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# If any GPU is available, the following code sets the memory growth option for the GPUs to True.\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# This function logs the content passed to it.\n",
    "def log(content):\n",
    "    if log_dir is not None:\n",
    "        log_file = log_dir + '/log.txt'\n",
    "        with open(log_file, 'a') as f:\n",
    "            print(content, file=f)\n",
    "\n",
    "# This function specifies the learning rate for each epoch based on the epoch number.        \n",
    "def lr_schedule(epoch):\n",
    "    lr = 1e-3\n",
    "    if epoch > 70:\n",
    "        lr *= 1e-3\n",
    "    if epoch > 60:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 40:\n",
    "        lr *= 1e-1 \n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "\n",
    "def load_data(dataset: str):\n",
    "    if dataset == 'MNIST':\n",
    "        mnist = tf.keras.datasets.mnist # load MNIST dataset\n",
    "        # split data into training and testing sets\n",
    "        (training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "        # reshape images to (28, 28, 1) size\n",
    "        training_images = training_images.reshape(60000, 28, 28, 1)\n",
    "        test_images = test_images.reshape(10000, 28, 28, 1)\n",
    "    elif dataset == 'CIFAR10':\n",
    "        cifar10 = tf.keras.datasets.cifar10\n",
    "        # split data into training and testing sets\n",
    "        (training_images, training_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "    # return training and testing images and labels\n",
    "    return training_images, training_labels, test_images, test_labels\n",
    "\n",
    "\n",
    "def get_unrelated_images(dataset: str, sample_rate):\n",
    "    \"\"\"Define a function named \"get_unrelated_images\" that takes in two parameters,\n",
    "        \n",
    "        dataset: string indicating the dataset ('MNIST' or 'CIFAR10') and\n",
    "        sample_rate: float indicating the proportion of images to use as training data.\"\"\"\n",
    "    # Create an empty list to store watermark images\n",
    "    watermark_images = []\n",
    "    # If the dataset is 'MNIST'\n",
    "    if dataset == 'MNIST':\n",
    "        # Set the file paths for the train images and train labels of 'emnist-letters' dataset\n",
    "        train_images_path = './data/emnist/emnist-letters-train-images-idx3-ubyte.gz'\n",
    "        train_labels_path = './data/emnist/emnist-letters-train-labels-idx1-ubyte.gz'\n",
    "        # Load images and labels from the train data file\n",
    "        with gzip.open(train_images_path, 'rb') as imgpath:\n",
    "            images = np.frombuffer(imgpath.read(), np.uint8, offset=16).reshape((-1, 28, 28, 1))\n",
    "        with gzip.open(train_labels_path, 'rb') as lbpath:\n",
    "            labels = np.frombuffer(lbpath.read(), np.uint8, offset=8)\n",
    "        # Check the labels of each image and store the images labeled as 23 (an unrelated class) in the watermark_images list\n",
    "        for i in range(images.shape[0]):\n",
    "            if labels[i] == 23:\n",
    "                watermark_images.append(images[i])\n",
    "    # If the dataset is 'CIFAR10'\n",
    "    elif dataset == 'CIFAR10':\n",
    "        # Load the MNIST dataset from keras datasets and store the training images and labels \n",
    "        mnist = tf.keras.datasets.mnist\n",
    "        (training_images, training_labels), (_, _) = mnist.load_data()\n",
    "        # Check the labels of each image and if it is labeled as 1 (an unrelated class), \n",
    "        # convert it into an RGB image of 32x32 dimensions and store in watermark_images list\n",
    "        for i in range(len(training_labels)):\n",
    "            if training_labels[i] == 1:\n",
    "                image = array_to_img(training_images[i].reshape(28, 28, 1))\n",
    "                image = image.convert(mode='RGB')\n",
    "                image = image.resize((32, 32))\n",
    "                image = img_to_array(image)\n",
    "                watermark_images.append(image)\n",
    "    # Shuffle the watermark images randomly\n",
    "    random.shuffle(watermark_images)\n",
    "    # Convert the watermark images list into a numpy array\n",
    "    watermark_images = np.array(watermark_images)\n",
    "    # Calculate the number of training samples based on the given sample rate\n",
    "    train_sample_number = int(len(watermark_images) * sample_rate)\n",
    "    # Split the watermark images into training and testing samples based on the calculated number of training samples\n",
    "    train_sample = watermark_images[:train_sample_number]\n",
    "    test_sample = watermark_images[train_sample_number:]\n",
    "    # Return the training and testing samples of unrelated images\n",
    "    return train_sample, test_sample\n",
    "\n",
    "\n",
    "def watermark(train_images, train_labels, old_label, new_label, sample_rate, dataset: str, wtype='content'):\n",
    "    \"\"\"prepare the dataset for training to embed the watermark \n",
    "    \n",
    "    args:\n",
    "        train_images: clean training images\n",
    "        train_labels: clean training labels\n",
    "        old_label: label for watermarking\n",
    "        new_label: label after watermarking\n",
    "        sample_rate: sample rate for embedding the watermark\n",
    "        wtype: watermarking type ('content', 'noise', 'unrelated')\n",
    "    \n",
    "    return:\n",
    "        processed training and testing dataset for watermarking\n",
    "    \"\"\"\n",
    "    if wtype == 'unrelated':\n",
    "        train_sample, test_sample = get_unrelated_images(dataset, sample_rate)\n",
    "    else:\n",
    "        watermark_images = []\n",
    "        for i in range(len(train_labels)):\n",
    "            if train_labels[i] == old_label:\n",
    "                watermark_images.append(train_images[i])\n",
    "                \n",
    "        if wtype == 'content':\n",
    "            # add the trigger (size= 8*8) at the right bottom corner \n",
    "            mark_image = load_img('./mark/apple_black.png', color_mode='grayscale', target_size=(8, 8))\n",
    "            for i in range(len(watermark_images)):\n",
    "                image = array_to_img(watermark_images[i])\n",
    "                image.paste(mark_image, box=(image.size[0] - 8, image.size[1] - 8))\n",
    "                watermark_images[i] = img_to_array(image)\n",
    "        elif wtype == 'noise':\n",
    "            for i in range(len(watermark_images)):\n",
    "                image = random_noise(watermark_images[i] / 255.0, seed=1)\n",
    "                image = image * 255.0\n",
    "                watermark_images[i] = image\n",
    "                \n",
    "        random.shuffle(watermark_images)\n",
    "        watermark_images = np.array(watermark_images)\n",
    "        train_sample_number = int(len(watermark_images) * sample_rate)\n",
    "        train_sample = watermark_images[:train_sample_number]\n",
    "        test_sample = watermark_images[train_sample_number:]\n",
    "\n",
    "    if dataset == 'MNIST':\n",
    "        return train_sample, np.ones(train_sample.shape[0]) * new_label, test_sample, np.ones(\n",
    "            test_sample.shape[0]) * new_label\n",
    "    elif dataset == 'CIFAR10':\n",
    "        return train_sample, np.ones((train_sample.shape[0], 1)) * new_label, test_sample, np.ones((\n",
    "            test_sample.shape[0], 1)) * new_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b3ec97",
   "metadata": {},
   "source": [
    "## Training resnet v1 on CIFAR10 Dataset with black-box watermarking approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8837a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':    \n",
    "    #wtype = 'content'\n",
    "    dataset = 'CIFAR10'\n",
    "    training_nums = 25000 \n",
    "    batch_size = 64\n",
    "    epochs = 30 # 80 for cifar10 and 10 for mnist\n",
    "    no_augmentation = False\n",
    "    old_label = 1\n",
    "    new_label = 3\n",
    "    log_dir = './logs' \n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "    print('log saved at ' + log_dir)\n",
    "    \n",
    "    \n",
    "    training_images, training_labels, test_images, test_labels = load_data(dataset)\n",
    "    #train_sample_images, train_sample_labels, test_sample_images, test_sample_labels = watermark(training_images,\n",
    "#                                                                                                  training_labels, old_label, new_label,\n",
    "#                                                                                                  0.1, dataset,\n",
    "#                                                                                                  wtype=wtype)\n",
    "\n",
    "    training_labels = tf.keras.utils.to_categorical(training_labels, 10)\n",
    "    test_labels = tf.keras.utils.to_categorical(test_labels, 10)\n",
    "    #train_sample_labels = tf.keras.utils.to_categorical(train_sample_labels, 10)\n",
    "    #test_sample_labels = tf.keras.utils.to_categorical(test_sample_labels, 10)\n",
    "\n",
    "    training_images = training_images / 255.0\n",
    "    test_images = test_images / 255.0\n",
    "    #train_sample_images = train_sample_images / 255.0\n",
    "    #test_sample_images = test_sample_images / 255.0\n",
    "    #training_all_images = np.concatenate((training_images[:training_nums], train_sample_images), axis=0)\n",
    "    #training_all_labels = np.concatenate((training_labels[:training_nums], train_sample_labels), axis=0)\n",
    "    \n",
    "    # This line sets the input shape of the model to the shape of the training images excluding the number of samples in the first dimension.\n",
    "    input_shape = training_images.shape[1:]\n",
    "    # This line creates a ResNet v1 model with a depth of 20 and the specified input shape.\n",
    "#     model = resnet_v1(input_shape=input_shape, depth=20)\n",
    "#     model =tf.keras.applications.resnet50.ResNet50(weights=\"imagenet\", input_shape=input_shape)\n",
    "#     model.add(tf.keras.layers.Dense(10, activation = 'softmax'))\n",
    "#     model = VGG16(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
    "    res_model = InceptionV3(\n",
    "        input_shape=input_shape,\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\"\n",
    "    )\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(res_model)\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "    #This line prints a summary of the model to the console using the specified log function.\n",
    "    model.summary(print_fn=log)\n",
    "    #This line creates a learning rate scheduler that reduces the learning rate over time according to the specified function.\n",
    "    reduce_lr = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "    # This line creates a learning rate reducer that reduces the learning rate by a factor of 0.1 when a metric has stopped improving.\n",
    "    lr_reducer = tf.keras.callbacks.ReduceLROnPlateau(factor=np.sqrt(0.1),cooldown=0,patience=5,min_lr=0.5e-6)\n",
    "    # This line compiles the model with the Adam optimizer, categorical cross-entropy loss, and accuracy metric.\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    if no_augmentation:\n",
    "        print('Not using data augmentation.')\n",
    "        history_nw = model.fit(training_images, training_labels,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=epochs,\n",
    "                            validation_data=(test_images, test_labels),\n",
    "                            callbacks=[reduce_lr, lr_reducer])\n",
    "    else:\n",
    "        print('Using real-time data augmentation.')\n",
    "        # # This line creates an image data generator with the specified augmentation parameters.\n",
    "        data_gen = ImageDataGenerator(\n",
    "            rotation_range=10,\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1\n",
    "        )\n",
    "        #  This line fits the model to the augmented data using the data generator, the specified number of epochs, and the specified validation data.\n",
    "        history_nw = model.fit(data_gen.flow(training_images, training_labels, batch_size=batch_size),\n",
    "                            epochs=epochs,\n",
    "                            validation_data=(test_images, test_labels),\n",
    "                            callbacks=[reduce_lr, lr_reducer],\n",
    "                            steps_per_epoch=training_images.shape[0] // batch_size)\n",
    "    #This line saves the training history of the model as a CSV file in the specified directory.\n",
    "    pd.DataFrame(history_w.history).to_csv(log_dir + '/log_nw.csv')\n",
    "    \n",
    "    if log_dir is not None:\n",
    "        model.save(log_dir + '/non-watermarked_model.h5')\n",
    "        #np.savez(log_dir + \"/content_trigger.npz\", test_sample_images=test_sample_images, test_sample_labels=test_sample_labels)\n",
    "        \n",
    "    loss, TSA = model.evaluate(test_images, test_labels)\n",
    "    print('Non-Watermarked Model Testing Accuracy: ', TSA)\n",
    "    print('Non-Watermarked Model Testing Loss: ', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafad63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':    \n",
    "    wtype = 'content'\n",
    "    dataset = 'CIFAR10'\n",
    "    training_nums = 25000 \n",
    "    batch_size = 64\n",
    "    epochs = 30 # 80 for cifar10 and 10 for mnist\n",
    "    no_augmentation = False\n",
    "    old_label = 1\n",
    "    new_label = 3\n",
    "    log_dir = './logs' \n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "    print('log saved at ' + log_dir)\n",
    "    \n",
    "    \n",
    "    training_images, training_labels, test_images, test_labels = load_data(dataset)\n",
    "    train_sample_images, train_sample_labels, test_sample_images, test_sample_labels = watermark(training_images,\n",
    "                                                                                                 training_labels, old_label, new_label,\n",
    "                                                                                                 0.1, dataset,\n",
    "                                                                                                 wtype=wtype)\n",
    "\n",
    "    training_labels = tf.keras.utils.to_categorical(training_labels, 10)\n",
    "    test_labels = tf.keras.utils.to_categorical(test_labels, 10)\n",
    "    train_sample_labels = tf.keras.utils.to_categorical(train_sample_labels, 10)\n",
    "    test_sample_labels = tf.keras.utils.to_categorical(test_sample_labels, 10)\n",
    "\n",
    "    training_images = training_images / 255.0\n",
    "    test_images = test_images / 255.0\n",
    "    train_sample_images = train_sample_images / 255.0\n",
    "    test_sample_images = test_sample_images / 255.0\n",
    "    training_all_images = np.concatenate((training_images[:training_nums], train_sample_images), axis=0)\n",
    "    training_all_labels = np.concatenate((training_labels[:training_nums], train_sample_labels), axis=0)\n",
    "    \n",
    "    input_shape = training_images.shape[1:] \n",
    "#     model = tf.keras.applications.ResNet50(include_top=True, weights=\"imagenet\")\n",
    "    res_model = VGG16(\n",
    "        input_shape=input_shape,\n",
    "        include_top=False,\n",
    "    )\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(res_model)\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "    model.summary(print_fn=log)\n",
    "    \n",
    "    reduce_lr = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "    lr_reducer = tf.keras.callbacks.ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                                                      cooldown=0,\n",
    "                                                      patience=5,\n",
    "                                                      min_lr=0.5e-6)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    if no_augmentation:\n",
    "        print('Not using data augmentation.')\n",
    "        history_w = model.fit(training_all_images, training_all_labels,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=epochs,\n",
    "                            validation_data=(test_images, test_labels),\n",
    "                            callbacks=[reduce_lr, lr_reducer])\n",
    "    else:\n",
    "        print('Using real-time data augmentation.')\n",
    "        data_gen = ImageDataGenerator(\n",
    "            rotation_range=10,\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1\n",
    "        )\n",
    "        history_w = model.fit(data_gen.flow(training_all_images, training_all_labels, batch_size=batch_size),\n",
    "                            epochs=epochs,\n",
    "                            validation_data=(test_images, test_labels),\n",
    "                            callbacks=[reduce_lr, lr_reducer],\n",
    "                            steps_per_epoch=training_all_images.shape[0] // batch_size)\n",
    "\n",
    "    pd.DataFrame(history_w.history).to_csv(log_dir + '/log_w.csv')\n",
    "    \n",
    "    if log_dir is not None:\n",
    "        model.save(log_dir + '/watermarked_model.h5')\n",
    "        np.savez(log_dir + \"/content_trigger.npz\", test_sample_images=test_sample_images, test_sample_labels=test_sample_labels)\n",
    "        \n",
    "    loss, TSA = model.evaluate(test_sample_images, test_sample_labels)\n",
    "    print('Watermarked Model Testing Accuracy: ', TSA)\n",
    "    print('Watermarked Model Testing Loss: ', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057b4ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "wtype = 'content'\n",
    "dataset = 'CIFAR10'\n",
    "old_label = 1\n",
    "new_label = 3\n",
    "training_images, training_labels, test_images, test_labels = load_data(dataset)\n",
    "train_sample_images, train_sample_labels, test_sample_images, test_sample_labels = watermark(training_images,\n",
    "                                                                                                 training_labels, old_label, new_label,\n",
    "                                                                                                 0.1, dataset,\n",
    "                                                                                                 wtype=wtype)\n",
    "\n",
    "train_sample_labels = tf.keras.utils.to_categorical(train_sample_labels, 10)\n",
    "test_sample_labels = tf.keras.utils.to_categorical(test_sample_labels, 10)\n",
    "train_sample_images = train_sample_images / 255.0\n",
    "test_sample_images = test_sample_images / 255.0\n",
    "\n",
    "# loading watermarked model \n",
    "model_wm = tf.keras.models.load_model('logs/watermarked_model.h5')\n",
    "\n",
    "# loading non-watermarked model \n",
    "model = tf.keras.models.load_model('logs/non-watermarked_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077a66e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = train_sample_images[0]\n",
    "label = train_sample_labels[0]\n",
    "print(\"label of selected image: \",label.max())\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d9505d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.expand_dims(img, axis=0)\n",
    "#watermarked model\n",
    "pred_wm = model_wm.predict(img)\n",
    "#non watermarked model\n",
    "pred = model.predict(img)\n",
    "\n",
    "# Compare the predicted classes\n",
    "predicted_class1 = pred_wm.argmax()\n",
    "predicted_class2 = pred.argmax()\n",
    "\n",
    "if predicted_class1 == predicted_class2:\n",
    "    print(\"The models made the same prediction.\")\n",
    "else:\n",
    "    print(\"The models made different predictions.\")\n",
    "    \n",
    "# Print the predicted class and confidence for each model\n",
    "confidence1 = pred_wm.max()\n",
    "confidence2 = pred.max()\n",
    "print(\"Original Label: \",label.max())\n",
    "print(f\"Watermarked Model  predicted class: {predicted_class1}, confidence: {confidence1}\")\n",
    "print(f\"Non Watermarked Model predicted class: {predicted_class2}, confidence: {confidence2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f402c8",
   "metadata": {},
   "source": [
    "# Steganography within Neural Network Architecture\n",
    "\n",
    "This notebook aims to explore the potential of steganography using neural network layers. The primary objective is to examine the feasibility of hiding sensitive information, such as text, images, videos, or software, within the parameters of a neural network model.\n",
    "\n",
    "The idea is to leverage the inherent complexity and non-linearity of the neural network layers to encode the secret data and obscure it from unauthorized access. By embedding the secret data in the model's parameters, it can potentially bypass traditional security measures such as encryption, making it a promising technique for secure communication.\n",
    "\n",
    "The notebook will also investigate how this technique impacts the model's performance, including factors such as accuracy, speed, and computational resources required. The results of this experiment will provide insights into the trade-offs between the level of secrecy achieved and the impact on the model's performance.\n",
    "\n",
    "It is worth noting that this is a proof-of-concept experiment and should not be used for any illegal or unethical purposes. The goal is to explore the possibilities and limitations of steganography with neural network layers and contribute to the advancement of secure communication methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55748a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many bits (LSB) to use from the fraction (mantissa) of the float values\n",
    "BITS_TO_USE = 16\n",
    "assert BITS_TO_USE <= 23, \"Can't be bigger then 23 bits\"\n",
    "\n",
    "DATA_FOLDER = \"data\"\n",
    "\n",
    "IMAGES_TO_TEST_ON = list(map(str, Path(DATA_FOLDER).glob(\"**/*.jpg\")))\n",
    "assert len(IMAGES_TO_TEST_ON) > 0, \"You'll need some images to test the network performance\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e36fc2",
   "metadata": {},
   "source": [
    "## Load the watermarked model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c95af81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any model can be used here\n",
    "model = tf.keras.models.load_model('logs/watermarked_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31884d2d",
   "metadata": {},
   "source": [
    "## Data storage capacity of the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e1a1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dictionary to store the storage capacity of each layer in megabytes\n",
    "layers_storage_capacity_mb: Dict[str, int] = {}\n",
    "# Loop over each layer in the model\n",
    "for l in model.layers:\n",
    "    # # Check if the layer is a Conv2D layer\n",
    "    if l.__class__.__name__ == \"Conv2D\":\n",
    "        # # Calculate the number of parameters in the layer and convert it to bytes\n",
    "        nb_params = np.prod(l.get_weights()[0].shape)\n",
    "        capacity_in_bytes = np.floor((nb_params * BITS_TO_USE) / 8).astype(int)\n",
    "        # # Store the storage capacity of the layer in megabytes in the dictionary\n",
    "        layers_storage_capacity_mb[l.name] = capacity_in_bytes / float(1<<20)\n",
    "# Create a bar plot of the storage capacity of each layer in the model        \n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 4))\n",
    "ax.bar(layers_storage_capacity_mb.keys(), layers_storage_capacity_mb.values())\n",
    "ax.tick_params(axis='x', labelrotation = 90)\n",
    "ax.set_xlabel(\"Layer Name\")\n",
    "ax.set_ylabel(\"Megabytes\")\n",
    "ax.set_title(f\"Storage capacity when using {BITS_TO_USE} bits from every float value\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078de9f5",
   "metadata": {},
   "source": [
    "## Inspect statistics for selected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc923c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layers with the most storage capacity\n",
    "# sorted(layers_storage_capacity_mb.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "\n",
    "# These layers will be modified to hide the secret\n",
    "\n",
    "# Selected layers (manual selection)\n",
    "# layer_names = [\"conv5_block1_2_conv\", \"conv5_block2_2_conv\", \"conv5_block3_2_conv\"]\n",
    "\n",
    "# All the Conv2D layers\n",
    "layer_names = list(layers_storage_capacity_mb.keys())\n",
    "# initialize an empty list to store the weights of selected layers\n",
    "selected_layers_weights = []\n",
    "# loop through each layer name in the model\n",
    "for n in layer_names:\n",
    "    # get the weight tensor of the layer as a numpy array and flatten it into a 1D array\n",
    "    v = model.get_layer(n).weights[0].numpy().ravel()\n",
    "    # extend the selected_layers_weights list with the flattened weight array of the current layer\n",
    "    selected_layers_weights.extend(v)\n",
    "# convert the selected_layers_weights list to a numpy array\n",
    "selected_layers_weights = np.array(selected_layers_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2198ac",
   "metadata": {},
   "source": [
    "## Basic statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3651fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of values in the selected_layers_weights\n",
    "nb_values = len(selected_layers_weights)\n",
    "# Get the minimum value in the selected_layers_weights\n",
    "min_value = selected_layers_weights.min()\n",
    "# Get the absolute minimum value in the selected_layers_weights\n",
    "abs_min_value = np.abs(selected_layers_weights).min()\n",
    "# Get the maximum value in the selected_layers_weights\n",
    "max_value = selected_layers_weights.max()\n",
    "# Calculate the mean of the values in the selected_layers_weights\n",
    "mean_value = selected_layers_weights.mean()\n",
    "# Count the number of values in the selected_layers_weights that are less than 10e-4 (very small values)\n",
    "nb_really_small_values = (abs(selected_layers_weights) < 10e-4).sum()\n",
    "# Count the number of values in the selected_layers_weights that are less than 10e-3 (small values)\n",
    "nb_small_values = (abs(selected_layers_weights) < 10e-3).sum()\n",
    "# Count the number of negative values in the selected_layers_weights\n",
    "nb_negative_values = (selected_layers_weights < 0).sum()\n",
    "# Count the number of positive values in the selected_layers_weights\n",
    "nb_positive_values = (selected_layers_weights > 0).sum()\n",
    "# Calculate the overall storage capacity of the selected_layers_weights in bytes and megabytes\n",
    "overall_storage_capacity_bytes = nb_values * BITS_TO_USE / 8\n",
    "overall_storage_capacity_mb = overall_storage_capacity_bytes // float(1<<20)\n",
    "# Print out the statistics and information for the selected_layers_weights\n",
    "print(f\"\"\"Stats for {layer_names}\n",
    "---\n",
    "Min: {min_value}\n",
    "Abs. Min {abs_min_value}\n",
    "Max: {max_value}\n",
    "Mean: {mean_value}\n",
    "---\n",
    "Nb total values: {nb_values}\n",
    "Nb values < 10e-4: {nb_really_small_values} - {nb_really_small_values/nb_values*100:.4f}%\n",
    "Nb values < 10e-3: {nb_small_values} - {nb_small_values/nb_values*100:.4f}%\n",
    "Nb negatives: {nb_negative_values} - {nb_negative_values/nb_values*100:.4f}%\n",
    "Nb positives: {nb_positive_values} - {nb_positive_values/nb_values*100:.4f}%\n",
    "---\n",
    "(Maximum) Storage capacity is {overall_storage_capacity_mb} MB for the {len(layer_names)} layers with the {BITS_TO_USE} bits modification\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756b2e6c",
   "metadata": {},
   "source": [
    "## Hide a secret in the layer\n",
    "\n",
    "### The secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dff87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a string variable containing the secret message to be hidden\n",
    "secret_to_hide = \"I am Rex and I would like to hide this message\"\n",
    "# Generate dummy data for overall storage capacity in bytes (this line is currently commented out)\n",
    "#secret_to_hide = dummy_data_generator.generate_dummy_data(overall_storage_capacity_bytes)\n",
    "# Convert the secret message string into a sequence of binary bits\n",
    "secret_bits = str_to_bits(secret_to_hide)\n",
    "# Calculate the number of floating point values needed to store the secret message\n",
    "nb_vals_needed = math.ceil(len(secret_bits) / BITS_TO_USE)\n",
    "# Print the number of floating point values needed to store the secret message, as well as the overall number of values that could be used for storage\n",
    "print(f\"We need {nb_vals_needed} float values to store the info\\nOverall number of values we could use: {nb_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2add5c53",
   "metadata": {},
   "source": [
    "### Hide it\n",
    "\n",
    "#### Store the original weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00973e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dict variable is created to hold the original weights for the selected layers\n",
    "original_weights_dict: dict = {}\n",
    "# Iterate through the list of layer names to get their original weights and store them in the dictionary\n",
    "for n in layer_names:\n",
    "    # model.get_layer(n).weights returns the trainable weights of the given layer as a list of weight tensors\n",
    "    # model.get_layer(n).weights[0] returns the first weight tensor of the given layer, which corresponds to the kernel\n",
    "    # model.get_layer(n).weights[0].numpy() returns the values of the kernel as a numpy array\n",
    "    # deepcopy() is used to create a new object with a copy of the original weight values, to avoid modifying the original\n",
    "    original_weights_dict[n] = deepcopy(model.get_layer(n).weights[0].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02741759",
   "metadata": {},
   "source": [
    "#### Create the modified ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affbf130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dict will hold the modified (secret hidden) weights for the layers\n",
    "modified_weights_dict = deepcopy(original_weights_dict)\n",
    "# Index of the last value used in a layer - this is needed because we don't necessary need\n",
    "# the same number of params for hiding some bits then all the layer parameters\n",
    "last_index_used_in_layer_dict: dict = {}\n",
    "\n",
    "# We are modifying the layers in a defined order to know what was changed exactly\n",
    "# This order is needed when we would like to recover the message\n",
    "\n",
    "# Variable which tracks the number of values changed so far (used to index the secret message bits)\n",
    "i = 0\n",
    "# This loop iterates over the layer names\n",
    "for n in layer_names:\n",
    "    # Check if we need more values to use to hide the secret, if not then we are done with modifying the layer's weights\n",
    "    if i >= nb_vals_needed:\n",
    "        break\n",
    "    # Get the weights of the current layer and its shape, then flatten the weights\n",
    "    w = modified_weights_dict[n]\n",
    "    w_shape = w.shape\n",
    "    w = w.ravel()\n",
    "    # Calculate the number of parameters in the layer\n",
    "    nb_params_in_layer: int = np.prod(w.shape)\n",
    "    # Loop over each parameter in the layer and hide secret bits in them\n",
    "    for j in range(nb_params_in_layer):\n",
    "        # Calculate the range of bits to hide in the current parameter\n",
    "        _from_index = i * BITS_TO_USE\n",
    "        _to_index = _from_index + BITS_TO_USE\n",
    "        bits_to_hide = secret_bits[_from_index:_to_index]\n",
    "        bits_to_hide = list(map(bool, bits_to_hide))\n",
    "\n",
    "        # Modify the fraction of the floating-point value of the parameter using the defined bits of the secret\n",
    "        x = FloatBinary(w[j])\n",
    "        fraction_modified = list(x.fraction)\n",
    "        if len(bits_to_hide) > 0:\n",
    "            fraction_modified[-BITS_TO_USE:] = bits_to_hide\n",
    "\n",
    "        x_modified = x.modify_clone(fraction=tuple(fraction_modified))\n",
    "        w[j] = x_modified.v\n",
    "        # Increment the number of values used to hide the secret\n",
    "        i += 1\n",
    "        \n",
    "        # Check if we need more values to use to hide the secret in the current layer, if not then we are done\n",
    "        if i >= nb_vals_needed:\n",
    "            break\n",
    "    # Record the index of the last parameter used to hide the secret in the current layer\n",
    "    last_index_used_in_layer_dict[n] = j\n",
    "    # Reshape the modified weights to their original shape and update the modified weights dictionary\n",
    "    w = w.reshape(w_shape)\n",
    "    modified_weights_dict[n] = w\n",
    "    # Print a message indicating the current layer is processed and the index of the last modified parameter\n",
    "    print(f\"Layer {n} is processed, last index modified: {j}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42a6d42",
   "metadata": {},
   "source": [
    "## Let's test the network and inspect the outputs\n",
    "\n",
    "### Dataset to test on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463a2632",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of images will be used for testing: {len(IMAGES_TO_TEST_ON)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c81958",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "# Define a function to read an image from a given file path\n",
    "def _read_image_from_path(image_path):\n",
    "    ## Read image file\n",
    "    image = tf.io.read_file(image_path)\n",
    "    # Decode image into a 3-channel uint8 tensor, ignoring any animation frames\n",
    "    image = tf.image.decode_image(image, channels=3, dtype=tf.uint8, expand_animations=False)\n",
    "    # Resize image to 32x32 pixels\n",
    "    image = tf.image.resize(image, (32, 32))\n",
    "    return image\n",
    "# Create a dataset of file paths to the images we want to test on\n",
    "dataset = tf.data.Dataset.from_tensor_slices(IMAGES_TO_TEST_ON)\n",
    "# Map the _read_image_from_path function onto each element in the dataset, using AUTOTUNE to parallelize processing\n",
    "dataset = dataset.map(_read_image_from_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# Batch the dataset into groups of 8 images, prefetching data to minimize data loading time\n",
    "dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381538a1",
   "metadata": {},
   "source": [
    "## Predictions made by the model\n",
    "\n",
    "### Original weights predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41146cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original weights to the model layers\n",
    "for n in layer_names:\n",
    "    w = original_weights_dict[n]\n",
    "    model.get_layer(n).set_weights([w, model.get_layer(n).get_weights()[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2493f4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_original = model.predict(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f91a91b",
   "metadata": {},
   "source": [
    "### Modified weights predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2075d974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the modified (secret is hidden) weights to the model layers\n",
    "for n in layer_names:\n",
    "    w = modified_weights_dict[n]\n",
    "    model.get_layer(n).set_weights([w, model.get_layer(n).get_weights()[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8540fbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_modified = model.predict(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2372871",
   "metadata": {},
   "source": [
    "## Differences in predictions\n",
    "\n",
    "### Raw prediction value comparisons (last layer output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a3aafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the absolute difference between predictions of two models and convert them to a 1-D array\n",
    "diff_abs = np.abs(preds_original - preds_modified).ravel()\n",
    "# Plot a histogram of absolute differences that are greater than or equal to zero\n",
    "plt.hist(diff_abs[diff_abs >= 0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876ed1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Min abs difference: {diff_abs.min()}\")\n",
    "print(f\"Max abs difference: {diff_abs.max()}\")\n",
    "print(f\"Number of changed prediction values: {(diff_abs > 0).sum()} / {len(diff_abs)} | {(diff_abs > 0).sum()/len(diff_abs)*100:.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2df9b1",
   "metadata": {},
   "source": [
    "### Change in predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f517016",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_changed_pred_labels = ((np.argmax(preds_original, 1) - np.argmax(preds_modified, 1)) > 0).sum()\n",
    "\n",
    "print(f\"Changed number of predictions: {nb_changed_pred_labels} / {len(IMAGES_TO_TEST_ON)} | {nb_changed_pred_labels / len(IMAGES_TO_TEST_ON)*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887515b3",
   "metadata": {},
   "source": [
    "### Recover the secret\n",
    "For recovering the secret we only need to know the layer names/indices in the model and the bits which we used for the \"encoding\".\n",
    "\n",
    "(And of course in a real life scenario we need direct access to the model's weights 😉)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88983579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the extracted bits of data\n",
    "hidden_data: List[bool] = []\n",
    "# Loop through each layer in the model and check if it was used to hide the secret\n",
    "for n in layer_names:\n",
    "    # If the layer was not used, skip it and continue to the next one\n",
    "    if n not in last_index_used_in_layer_dict.keys():\n",
    "        continue\n",
    "    \n",
    "   # Get the modified weights for the layer and reshape them into a 1D array\n",
    "    w = modified_weights_dict[n]\n",
    "    w_shape = w.shape\n",
    "    w = w.ravel()\n",
    "    # Calculate the number of parameters in the layer\n",
    "    nb_params_in_layer: int = np.prod(w.shape)\n",
    "    # Loop through the first few weights in the layer and extract the hidden bits from them\n",
    "    for i in range(last_index_used_in_layer_dict[n]+1):\n",
    "        x = FloatBinary(w[i])\n",
    "        hidden_bits = x.fraction[-BITS_TO_USE:]\n",
    "        hidden_data.extend(hidden_bits)\n",
    "    # Print a message indicating that the layer has been processed and its bits have been extracted    \n",
    "    print(f\"Layer {n} is processed, bits are extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ec773a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following line decodes the hidden data, which is a list of bits, into a string.\n",
    "recovered_message: str = bits_to_str(list(map(int, hidden_data)))\n",
    "# This line sets a variable \"chars_to_display\" to 100, which is the number of characters from the beginning of the strings that will be displayed. \n",
    "chars_to_display = 100\n",
    "# This line prints the original message to the console, only displaying the first \"chars_to_display\" characters, followed by ellipsis.\n",
    "print(f\"--Original string:--\\n'{secret_to_hide[:chars_to_display]}...'\")\n",
    "# This line prints the recovered message to the console, only displaying the first \"chars_to_display\" characters, followed by ellipsis.\n",
    "print(f\"--Recovered string:--\\n'{recovered_message[:chars_to_display]}...'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8bf06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that takes a string as input and returns its MD5 hash value as a string.\n",
    "def hash_str(s: str) -> str:\n",
    "    return hashlib.md5(s.encode(\"ascii\")).hexdigest()\n",
    "# Check if the MD5 hash value of the recovered message is the same as the MD5 hash value of the secret message.\n",
    "# If they match, print a success message.\n",
    "# Otherwise, print a message indicating that the recovered message is not the same as the original one.\n",
    "if hash_str(recovered_message) == hash_str(secret_to_hide):\n",
    "    print(\"Successful secret hiding and recovery! 🥳\")\n",
    "else:\n",
    "    print(\"Recovered message is not the same as the original one 🤨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb829cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b3545c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8da0696",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d487ee0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Embedding watermarks into Deep Neural Networks\n",
    "\n",
    "Digital watermarking technology is used to protect intellectual property or detect intellectual property infringement of trained models.\n",
    "\n",
    "### Following code embeds watermarks into a resnet architecture using black box watermarking approach. The dataset used is CIFAR10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d613873d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60223482",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img, array_to_img, ImageDataGenerator\n",
    "import gzip\n",
    "from skimage.util.noise import random_noise\n",
    "from resnet20 import resnet_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54d81fd7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from tensorflow.keras.layers import AveragePooling2D, Input, Flatten\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "\n",
    "def resnet_layer(inputs, num_filters=16, kernel_size=3, strides=1, activation='relu', batch_normalization=True, conv_first=True):\n",
    "    conv = Conv2D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=l2(1e-4))\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def resnet_v1(input_shape, depth, num_classes=10):\n",
    "    \"\"\"ResNet Version 1 Model builder\n",
    "    \n",
    "    args:\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "\n",
    "    return:\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 6 != 0:\n",
    "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44)')\n",
    "    # Start model definition.\n",
    "    num_filters = 16\n",
    "    num_res_blocks = int((depth - 2) / 6)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = resnet_layer(inputs=inputs)\n",
    "    # Instantiate the stack of residual units\n",
    "    for stack in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            strides = 1\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                strides = 2  # downsample\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters,\n",
    "                             strides=strides)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters,\n",
    "                             activation=None)\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "            x = Activation('relu')(x)\n",
    "        num_filters *= 2\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v1 does not use BN after last shortcut connection-ReLU\n",
    "    x = AveragePooling2D(pool_size=4)(x)\n",
    "    y = Flatten()(x)\n",
    "    y = Dense(num_classes,\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "    outputs = Activation('softmax')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e4ffe6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Defining Essential Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "379c3375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.experimental.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5841063f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "def log(content):\n",
    "    if log_dir is not None:\n",
    "        log_file = log_dir + '/log.txt'\n",
    "        with open(log_file, 'a') as f:\n",
    "            print(content, file=f)\n",
    "\n",
    "        \n",
    "def lr_schedule(epoch):\n",
    "    lr = 1e-3\n",
    "    if epoch > 70:\n",
    "        lr *= 1e-3\n",
    "    if epoch > 60:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 40:\n",
    "        lr *= 1e-1 \n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "\n",
    "def load_data(dataset: str):\n",
    "    if dataset == 'MNIST':\n",
    "        mnist = tf.keras.datasets.mnist\n",
    "        (training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "        training_images = training_images.reshape(60000, 28, 28, 1)\n",
    "        test_images = test_images.reshape(10000, 28, 28, 1)\n",
    "    elif dataset == 'CIFAR10':\n",
    "        cifar10 = tf.keras.datasets.cifar10\n",
    "        (training_images, training_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "\n",
    "    return training_images, training_labels, test_images, test_labels\n",
    "\n",
    "\n",
    "def get_unrelated_images(dataset: str, sample_rate):\n",
    "    watermark_images = []\n",
    "    if dataset == 'MNIST':\n",
    "        # e-mnist for the mnist dataset \n",
    "        train_images_path = './data/emnist/emnist-letters-train-images-idx3-ubyte.gz'\n",
    "        train_labels_path = './data/emnist/emnist-letters-train-labels-idx1-ubyte.gz'\n",
    "        with gzip.open(train_images_path, 'rb') as imgpath:\n",
    "            images = np.frombuffer(imgpath.read(), np.uint8, offset=16).reshape((-1, 28, 28, 1))\n",
    "        with gzip.open(train_labels_path, 'rb') as lbpath:\n",
    "            labels = np.frombuffer(lbpath.read(), np.uint8, offset=8)\n",
    "        for i in range(images.shape[0]):\n",
    "            if labels[i] == 23:\n",
    "                watermark_images.append(images[i])\n",
    "    elif dataset == 'CIFAR10':\n",
    "        # mnist for the cifar10 dataset \n",
    "        mnist = tf.keras.datasets.mnist\n",
    "        (training_images, training_labels), (_, _) = mnist.load_data()\n",
    "        for i in range(len(training_labels)):\n",
    "            if training_labels[i] == 1:\n",
    "                image = array_to_img(training_images[i].reshape(28, 28, 1))\n",
    "                image = image.convert(mode='RGB')\n",
    "                image = image.resize((32, 32))\n",
    "                image = img_to_array(image)\n",
    "                watermark_images.append(image)\n",
    "\n",
    "    random.shuffle(watermark_images)\n",
    "    watermark_images = np.array(watermark_images)\n",
    "    train_sample_number = int(len(watermark_images) * sample_rate)\n",
    "    train_sample = watermark_images[:train_sample_number]\n",
    "    test_sample = watermark_images[train_sample_number:]\n",
    "\n",
    "    return train_sample, test_sample\n",
    "\n",
    "\n",
    "def watermark(train_images, train_labels, old_label, new_label, sample_rate, dataset: str, wtype='content'):\n",
    "    \"\"\"prepare the dataset for training to embed the watermark \n",
    "    \n",
    "    args:\n",
    "        train_images: clean training images\n",
    "        train_labels: clean training labels\n",
    "        old_label: label for watermarking\n",
    "        new_label: label after watermarking\n",
    "        sample_rate: sample rate for embedding the watermark\n",
    "        wtype: watermarking type ('content', 'noise', 'unrelated')\n",
    "    \n",
    "    return:\n",
    "        processed training and testing dataset for watermarking\n",
    "    \"\"\"\n",
    "    if wtype == 'unrelated':\n",
    "        train_sample, test_sample = get_unrelated_images(dataset, sample_rate)\n",
    "    else:\n",
    "        watermark_images = []\n",
    "        for i in range(len(train_labels)):\n",
    "            if train_labels[i] == old_label:\n",
    "                watermark_images.append(train_images[i])\n",
    "                \n",
    "        if wtype == 'content':\n",
    "            # add the trigger (size= 8*8) at the right bottom corner \n",
    "            mark_image = load_img('./mark/apple_black.png', color_mode='grayscale', target_size=(8, 8))\n",
    "            for i in range(len(watermark_images)):\n",
    "                image = array_to_img(watermark_images[i])\n",
    "                image.paste(mark_image, box=(image.size[0] - 8, image.size[1] - 8))\n",
    "                watermark_images[i] = img_to_array(image)\n",
    "        elif wtype == 'noise':\n",
    "            for i in range(len(watermark_images)):\n",
    "                image = random_noise(watermark_images[i] / 255.0, seed=1)\n",
    "                image = image * 255.0\n",
    "                watermark_images[i] = image\n",
    "                \n",
    "        random.shuffle(watermark_images)\n",
    "        watermark_images = np.array(watermark_images)\n",
    "        train_sample_number = int(len(watermark_images) * sample_rate)\n",
    "        train_sample = watermark_images[:train_sample_number]\n",
    "        test_sample = watermark_images[train_sample_number:]\n",
    "\n",
    "    if dataset == 'MNIST':\n",
    "        return train_sample, np.ones(train_sample.shape[0]) * new_label, test_sample, np.ones(\n",
    "            test_sample.shape[0]) * new_label\n",
    "    elif dataset == 'CIFAR10':\n",
    "        return train_sample, np.ones((train_sample.shape[0], 1)) * new_label, test_sample, np.ones((\n",
    "            test_sample.shape[0], 1)) * new_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db01f3f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training resnet v1 on CIFAR10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3a67511",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log saved at ./logs\n",
      "Using real-time data augmentation.\n",
      "Learning rate:  0.001\n",
      "Epoch 1/30\n",
      "781/781 [==============================] - 41s 38ms/step - loss: 1.6448 - accuracy: 0.4678 - val_loss: 1.3160 - val_accuracy: 0.5871 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 2/30\n",
      "781/781 [==============================] - 29s 37ms/step - loss: 1.2390 - accuracy: 0.6156 - val_loss: 1.4242 - val_accuracy: 0.5861 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 3/30\n",
      "781/781 [==============================] - 29s 37ms/step - loss: 1.0689 - accuracy: 0.6781 - val_loss: 1.1297 - val_accuracy: 0.6671 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 4/30\n",
      "781/781 [==============================] - 29s 37ms/step - loss: 0.9708 - accuracy: 0.7140 - val_loss: 1.0432 - val_accuracy: 0.7006 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 5/30\n",
      "781/781 [==============================] - 28s 36ms/step - loss: 0.8818 - accuracy: 0.7476 - val_loss: 1.1845 - val_accuracy: 0.6727 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 6/30\n",
      "781/781 [==============================] - 32s 41ms/step - loss: 0.8275 - accuracy: 0.7664 - val_loss: 0.8578 - val_accuracy: 0.7599 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 7/30\n",
      "781/781 [==============================] - 29s 37ms/step - loss: 0.7849 - accuracy: 0.7831 - val_loss: 1.0214 - val_accuracy: 0.7259 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 8/30\n",
      "781/781 [==============================] - 28s 36ms/step - loss: 0.7414 - accuracy: 0.7999 - val_loss: 0.8418 - val_accuracy: 0.7718 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 9/30\n",
      "781/781 [==============================] - 28s 36ms/step - loss: 0.7167 - accuracy: 0.8077 - val_loss: 0.9538 - val_accuracy: 0.7345 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 10/30\n",
      "781/781 [==============================] - 29s 37ms/step - loss: 0.6862 - accuracy: 0.8197 - val_loss: 0.8181 - val_accuracy: 0.7857 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 11/30\n",
      "781/781 [==============================] - 28s 36ms/step - loss: 0.6676 - accuracy: 0.8262 - val_loss: 0.8843 - val_accuracy: 0.7607 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 12/30\n",
      "781/781 [==============================] - 30s 39ms/step - loss: 0.6404 - accuracy: 0.8384 - val_loss: 1.0423 - val_accuracy: 0.7327 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 13/30\n",
      "781/781 [==============================] - 29s 37ms/step - loss: 0.6298 - accuracy: 0.8391 - val_loss: 0.8063 - val_accuracy: 0.7885 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 14/30\n",
      "781/781 [==============================] - 28s 36ms/step - loss: 0.6084 - accuracy: 0.8477 - val_loss: 0.8154 - val_accuracy: 0.7981 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 15/30\n",
      "781/781 [==============================] - 28s 36ms/step - loss: 0.6026 - accuracy: 0.8512 - val_loss: 0.7174 - val_accuracy: 0.8247 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 16/30\n",
      "781/781 [==============================] - 28s 36ms/step - loss: 0.5862 - accuracy: 0.8563 - val_loss: 0.7775 - val_accuracy: 0.8087 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 17/30\n",
      "781/781 [==============================] - 28s 36ms/step - loss: 0.5782 - accuracy: 0.8600 - val_loss: 0.9212 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 18/30\n",
      "781/781 [==============================] - 28s 36ms/step - loss: 0.5606 - accuracy: 0.8671 - val_loss: 0.7810 - val_accuracy: 0.8076 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 19/30\n",
      "781/781 [==============================] - 28s 36ms/step - loss: 0.5514 - accuracy: 0.8706 - val_loss: 0.7906 - val_accuracy: 0.8002 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 20/30\n",
      "781/781 [==============================] - 28s 35ms/step - loss: 0.5461 - accuracy: 0.8718 - val_loss: 0.6741 - val_accuracy: 0.8410 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 21/30\n",
      "781/781 [==============================] - 28s 36ms/step - loss: 0.5413 - accuracy: 0.8749 - val_loss: 0.6911 - val_accuracy: 0.8344 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 22/30\n",
      "781/781 [==============================] - 28s 35ms/step - loss: 0.5279 - accuracy: 0.8805 - val_loss: 0.6985 - val_accuracy: 0.8318 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 23/30\n",
      "781/781 [==============================] - 28s 36ms/step - loss: 0.5200 - accuracy: 0.8837 - val_loss: 0.8116 - val_accuracy: 0.8118 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 24/30\n",
      "781/781 [==============================] - 31s 40ms/step - loss: 0.5227 - accuracy: 0.8816 - val_loss: 0.9858 - val_accuracy: 0.7735 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 25/30\n",
      "781/781 [==============================] - 28s 36ms/step - loss: 0.5174 - accuracy: 0.8838 - val_loss: 0.8117 - val_accuracy: 0.8133 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 26/30\n",
      "781/781 [==============================] - 28s 36ms/step - loss: 0.5036 - accuracy: 0.8896 - val_loss: 0.8927 - val_accuracy: 0.7931 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 27/30\n",
      "781/781 [==============================] - 28s 36ms/step - loss: 0.4993 - accuracy: 0.8924 - val_loss: 1.0116 - val_accuracy: 0.7640 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 28/30\n",
      "781/781 [==============================] - 28s 36ms/step - loss: 0.4967 - accuracy: 0.8929 - val_loss: 0.7887 - val_accuracy: 0.8100 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 29/30\n",
      "781/781 [==============================] - 28s 36ms/step - loss: 0.4953 - accuracy: 0.8941 - val_loss: 0.6977 - val_accuracy: 0.8396 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 30/30\n",
      "781/781 [==============================] - 28s 35ms/step - loss: 0.4899 - accuracy: 0.8969 - val_loss: 0.8339 - val_accuracy: 0.8074 - lr: 0.0010\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.8339 - accuracy: 0.8074\n",
      "Original Model Testing Accuracy:  0.8073999881744385\n",
      "Original Model Testing Loss:  0.8338788151741028\n"
     ]
    }
   ],
   "source": [
    "log_dir = './logs' \n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "print('log saved at ' + log_dir)\n",
    "\n",
    "dataset = 'CIFAR10'\n",
    "batch_size = 64\n",
    "epochs = 30   \n",
    "\n",
    "\n",
    "training_images, training_labels, test_images, test_labels = load_data(dataset)\n",
    "training_images = training_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "training_labels = tf.keras.utils.to_categorical(training_labels, 10)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, 10)\n",
    "\n",
    "input_shape = training_images.shape[1:]\n",
    "model = resnet_v1(input_shape=input_shape, depth=20) \n",
    "model.summary(print_fn=log)\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "lr_reducer = tf.keras.callbacks.ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                                                      cooldown=0,\n",
    "                                                      patience=5,\n",
    "                                                      min_lr=0.5e-6)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "print('Using real-time data augmentation.')\n",
    "data_gen = ImageDataGenerator(\n",
    "            rotation_range=10,\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1\n",
    "        )\n",
    "history = model.fit(data_gen.flow(training_images, training_labels, batch_size=batch_size),\n",
    "                            epochs=epochs,\n",
    "                            validation_data=(test_images, test_labels),\n",
    "                            callbacks=[reduce_lr, lr_reducer],\n",
    "                            steps_per_epoch=training_images.shape[0] // batch_size)\n",
    "\n",
    "pd.DataFrame(history.history).to_csv(log_dir + '/log.csv')\n",
    "\n",
    "loss, acc = model.evaluate(test_images, test_labels, verbose=1)\n",
    "print('Original Model Testing Accuracy: ', acc)\n",
    "print('Original Model Testing Loss: ', loss)\n",
    "\n",
    "if log_dir is not None:\n",
    "    model.save(log_dir + '/original_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a0a4c2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training resnet v1 on CIFAR10 Dataset with black-box watermarking approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2477dc81",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log saved at ./logs\n",
      "Using real-time data augmentation.\n",
      "Learning rate:  0.001\n",
      "Epoch 1/30\n",
      "398/398 [==============================] - 19s 41ms/step - loss: 1.8579 - accuracy: 0.3905 - val_loss: 1.7988 - val_accuracy: 0.4235 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 2/30\n",
      "398/398 [==============================] - 16s 39ms/step - loss: 1.4815 - accuracy: 0.5188 - val_loss: 2.6490 - val_accuracy: 0.3754 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 3/30\n",
      "398/398 [==============================] - 16s 39ms/step - loss: 1.2932 - accuracy: 0.5947 - val_loss: 2.4316 - val_accuracy: 0.3989 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 4/30\n",
      "398/398 [==============================] - 16s 39ms/step - loss: 1.1620 - accuracy: 0.6391 - val_loss: 1.5222 - val_accuracy: 0.5429 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 5/30\n",
      "398/398 [==============================] - 16s 39ms/step - loss: 1.0767 - accuracy: 0.6721 - val_loss: 1.5486 - val_accuracy: 0.5724 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 6/30\n",
      "398/398 [==============================] - 16s 39ms/step - loss: 1.0134 - accuracy: 0.7010 - val_loss: 1.0793 - val_accuracy: 0.6794 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 7/30\n",
      "398/398 [==============================] - 16s 39ms/step - loss: 0.9481 - accuracy: 0.7205 - val_loss: 1.1695 - val_accuracy: 0.6594 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 8/30\n",
      "398/398 [==============================] - 16s 39ms/step - loss: 0.9044 - accuracy: 0.7362 - val_loss: 1.3734 - val_accuracy: 0.6052 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 9/30\n",
      "398/398 [==============================] - 16s 39ms/step - loss: 0.8520 - accuracy: 0.7565 - val_loss: 1.2076 - val_accuracy: 0.6686 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 10/30\n",
      "398/398 [==============================] - 16s 40ms/step - loss: 0.8209 - accuracy: 0.7662 - val_loss: 1.4792 - val_accuracy: 0.6158 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 11/30\n",
      "398/398 [==============================] - 16s 39ms/step - loss: 0.7952 - accuracy: 0.7773 - val_loss: 0.9743 - val_accuracy: 0.7311 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 12/30\n",
      "398/398 [==============================] - 16s 39ms/step - loss: 0.7661 - accuracy: 0.7877 - val_loss: 0.9387 - val_accuracy: 0.7336 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 13/30\n",
      "398/398 [==============================] - 16s 39ms/step - loss: 0.7378 - accuracy: 0.7990 - val_loss: 1.1381 - val_accuracy: 0.6907 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 14/30\n",
      "398/398 [==============================] - 16s 39ms/step - loss: 0.7186 - accuracy: 0.8047 - val_loss: 0.9705 - val_accuracy: 0.7380 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 15/30\n",
      "398/398 [==============================] - 16s 39ms/step - loss: 0.6944 - accuracy: 0.8126 - val_loss: 1.0087 - val_accuracy: 0.7300 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 16/30\n",
      "398/398 [==============================] - 16s 39ms/step - loss: 0.6682 - accuracy: 0.8256 - val_loss: 1.1714 - val_accuracy: 0.6972 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 17/30\n",
      "398/398 [==============================] - 16s 39ms/step - loss: 0.6558 - accuracy: 0.8277 - val_loss: 1.2302 - val_accuracy: 0.6772 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 18/30\n",
      "398/398 [==============================] - 16s 39ms/step - loss: 0.6439 - accuracy: 0.8333 - val_loss: 1.0973 - val_accuracy: 0.7210 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 19/30\n",
      "398/398 [==============================] - 16s 39ms/step - loss: 0.6227 - accuracy: 0.8422 - val_loss: 1.2000 - val_accuracy: 0.7072 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 20/30\n",
      "398/398 [==============================] - 16s 40ms/step - loss: 0.6058 - accuracy: 0.8474 - val_loss: 1.0406 - val_accuracy: 0.7354 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 21/30\n",
      "398/398 [==============================] - 16s 39ms/step - loss: 0.5967 - accuracy: 0.8539 - val_loss: 1.0226 - val_accuracy: 0.7463 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 22/30\n",
      "398/398 [==============================] - 16s 39ms/step - loss: 0.5845 - accuracy: 0.8570 - val_loss: 0.9245 - val_accuracy: 0.7625 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 23/30\n",
      "398/398 [==============================] - 16s 40ms/step - loss: 0.5728 - accuracy: 0.8615 - val_loss: 1.0424 - val_accuracy: 0.7380 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 24/30\n",
      "398/398 [==============================] - 16s 39ms/step - loss: 0.5623 - accuracy: 0.8650 - val_loss: 0.8738 - val_accuracy: 0.7832 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 25/30\n",
      "398/398 [==============================] - 16s 40ms/step - loss: 0.5505 - accuracy: 0.8712 - val_loss: 0.9544 - val_accuracy: 0.7688 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 26/30\n",
      "398/398 [==============================] - 16s 39ms/step - loss: 0.5349 - accuracy: 0.8740 - val_loss: 1.0515 - val_accuracy: 0.7594 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 27/30\n",
      "398/398 [==============================] - 16s 39ms/step - loss: 0.5292 - accuracy: 0.8782 - val_loss: 0.9345 - val_accuracy: 0.7797 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 28/30\n",
      "398/398 [==============================] - 16s 39ms/step - loss: 0.5282 - accuracy: 0.8782 - val_loss: 1.0616 - val_accuracy: 0.7589 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 29/30\n",
      "398/398 [==============================] - 16s 39ms/step - loss: 0.5132 - accuracy: 0.8839 - val_loss: 0.9437 - val_accuracy: 0.7746 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 30/30\n",
      "398/398 [==============================] - 16s 39ms/step - loss: 0.5018 - accuracy: 0.8906 - val_loss: 1.0501 - val_accuracy: 0.7494 - lr: 0.0010\n",
      "141/141 [==============================] - 2s 11ms/step - loss: 0.1894 - accuracy: 1.0000\n",
      "Watermarked Model Testing Accuracy:  1.0\n",
      "Watermarked Model Testing Loss:  0.18940557539463043\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':    \n",
    "    wtype = 'content'\n",
    "    dataset = 'CIFAR10'\n",
    "    training_nums = 25000 \n",
    "    batch_size = 64\n",
    "    epochs = 30 # 80 for cifar10 and 10 for mnist\n",
    "    no_augmentation = False\n",
    "    old_label = 1\n",
    "    new_label = 3\n",
    "    log_dir = './logs' \n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "    print('log saved at ' + log_dir)\n",
    "    \n",
    "    \n",
    "    training_images, training_labels, test_images, test_labels = load_data(dataset)\n",
    "    train_sample_images, train_sample_labels, test_sample_images, test_sample_labels = watermark(training_images,\n",
    "                                                                                                 training_labels, old_label, new_label,\n",
    "                                                                                                 0.1, dataset,\n",
    "                                                                                                 wtype=wtype)\n",
    "\n",
    "    training_labels = tf.keras.utils.to_categorical(training_labels, 10)\n",
    "    test_labels = tf.keras.utils.to_categorical(test_labels, 10)\n",
    "    train_sample_labels = tf.keras.utils.to_categorical(train_sample_labels, 10)\n",
    "    test_sample_labels = tf.keras.utils.to_categorical(test_sample_labels, 10)\n",
    "\n",
    "    training_images = training_images / 255.0\n",
    "    test_images = test_images / 255.0\n",
    "    train_sample_images = train_sample_images / 255.0\n",
    "    test_sample_images = test_sample_images / 255.0\n",
    "    training_all_images = np.concatenate((training_images[:training_nums], train_sample_images), axis=0)\n",
    "    training_all_labels = np.concatenate((training_labels[:training_nums], train_sample_labels), axis=0)\n",
    "    \n",
    "    input_shape = training_images.shape[1:]\n",
    "    model = resnet_v1(input_shape=input_shape, depth=20) \n",
    "    model.summary(print_fn=log)\n",
    "    \n",
    "    reduce_lr = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "    lr_reducer = tf.keras.callbacks.ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                                                      cooldown=0,\n",
    "                                                      patience=5,\n",
    "                                                      min_lr=0.5e-6)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    if no_augmentation:\n",
    "        print('Not using data augmentation.')\n",
    "        history0 = model.fit(training_all_images, training_all_labels,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=epochs,\n",
    "                            validation_data=(test_images, test_labels),\n",
    "                            callbacks=[reduce_lr, lr_reducer])\n",
    "    else:\n",
    "        print('Using real-time data augmentation.')\n",
    "        data_gen = ImageDataGenerator(\n",
    "            rotation_range=10,\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1\n",
    "        )\n",
    "        history0 = model.fit(data_gen.flow(training_all_images, training_all_labels, batch_size=batch_size),\n",
    "                            epochs=epochs,\n",
    "                            validation_data=(test_images, test_labels),\n",
    "                            callbacks=[reduce_lr, lr_reducer],\n",
    "                            steps_per_epoch=training_all_images.shape[0] // batch_size)\n",
    "\n",
    "    pd.DataFrame(history.history).to_csv(log_dir + '/log.csv')\n",
    "    \n",
    "    if log_dir is not None:\n",
    "        model.save(log_dir + '/watermarked_model.h5')\n",
    "        np.savez(log_dir + \"/content_trigger.npz\", test_sample_images=test_sample_images, test_sample_labels=test_sample_labels)\n",
    "        \n",
    "    loss, TSA = model.evaluate(test_sample_images, test_sample_labels)\n",
    "    print('Watermarked Model Testing Accuracy: ', TSA)\n",
    "    print('Watermarked Model Testing Loss: ', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33103ff",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
